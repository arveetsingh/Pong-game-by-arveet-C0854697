{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of pg-from-scratch.ipynb","provenance":[{"file_id":"https://github.com/DJCordhose/ai/blob/master/notebooks/rl/pg-from-scratch.ipynb","timestamp":1660995902919}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**Pong game with varying neurons and learning** **rate** "],"metadata":{"id":"c1PvCKPSFVbl"}},{"metadata":{"id":"uF9MAVI16huj"},"cell_type":"code","source":["# !apt-get install python-opengl -y  >/dev/null\n","# !apt install xvfb -y >/dev/null"],"execution_count":null,"outputs":[]},{"metadata":{"id":"fSC11TfN6p69"},"cell_type":"code","source":["# !pip install pyvirtualdisplay >/dev/null\n","# !pip install piglet >/dev/null"],"execution_count":null,"outputs":[]},{"metadata":{"id":"caiHE2hy6xrf"},"cell_type":"code","source":["# from pyvirtualdisplay import Display\n","# display = Display(visible=0, size=(1400, 900))\n","# display.start()"],"execution_count":null,"outputs":[]},{"metadata":{"id":"cWACPRL869I4"},"cell_type":"code","source":["!pip install gym >/dev/null"],"execution_count":null,"outputs":[]},{"metadata":{"id":"2Os6feRY6ec_"},"cell_type":"code","source":["!pip install JSAnimation >/dev/null"],"execution_count":null,"outputs":[]},{"metadata":{"id":"wotUOa_e6edP"},"cell_type":"code","source":["%matplotlib inline\n","from JSAnimation.IPython_display import display_animation\n","from matplotlib import animation\n","import matplotlib.pyplot as plt\n","from IPython.display import HTML\n","\n","def display_frames_as_gif(frames):\n","    \"\"\"\n","    Displays a list of frames as a gif, with controls\n","    \"\"\"\n","    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n","    patch = plt.imshow(frames[0])\n","    plt.axis('off')\n","\n","    def animate(i):\n","        patch.set_data(frames[i])\n","\n","    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n","    display(display_animation(anim, default_mode='once'))"],"execution_count":null,"outputs":[]},{"metadata":{"id":"R66_INeZ9nYX"},"cell_type":"markdown","source":["## Step 2: Playing Pong"]},{"metadata":{"id":"MtT2GyK_6edc","outputId":"34623d6d-4672-4bbf-8eca-9b7b69da38bd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660966985385,"user_tz":240,"elapsed":10477,"user":{"displayName":"","userId":""}}},"cell_type":"code","source":["%pip install -U gym>=0.21.0\n","%pip install -U gym[atari,accept-rom-license]\n","import gym\n","env = gym.make('Pong-v0')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.2)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.5.0)\n","Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.12.0)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n","Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.4.2)\n","Requirement already satisfied: ale-py~=0.7.5 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.7.5)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n","Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (0.4.2)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:594: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n","  f\"The environment {id} is out of date. You should consider \"\n","/usr/local/lib/python3.7/dist-packages/gym/core.py:318: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n","/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"]}]},{"metadata":{"id":"oRE6WmXQJ1Z0","outputId":"7249b1a0-5bbe-4495-d4a1-aa1fe3d95288","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660966985387,"user_tz":240,"elapsed":65,"user":{"displayName":"","userId":""}}},"cell_type":"code","source":["env.action_space"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Discrete(6)"]},"metadata":{},"execution_count":23}]},{"metadata":{"id":"yl_9d4HFJ31W","outputId":"2394780a-49e5-499e-88d7-1270e7f82e5c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660966985390,"user_tz":240,"elapsed":45,"user":{"displayName":"","userId":""}}},"cell_type":"code","source":["env.observation_space"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Box(0, 255, (210, 160, 3), uint8)"]},"metadata":{},"execution_count":24}]},{"metadata":{"id":"trwRXI-h6eeI","outputId":"61b7a1bd-91c2-44fb-d5f0-47c02a566f0f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660966986382,"user_tz":240,"elapsed":1020,"user":{"displayName":"","userId":""}}},"cell_type":"code","source":["# Run a demo of the environment\n","observation = env.reset()\n","cumulated_reward = 0\n","\n","frames = []\n","for t in range(1000):\n","#     print(observation)\n","    frames.append(env.render(mode = 'rgb_array'))\n","    # very stupid agent, just makes a random action within the allowd action space\n","    action = env.action_space.sample()\n","#     print(\"Action: {}\".format(t+1))    \n","    observation, reward, done, info = env.step(action)\n","#     print(reward)\n","    cumulated_reward += reward\n","    if done:\n","        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","        break\n","print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","\n","env.close()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/core.py:44: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  \"The argument mode in render method is deprecated; \"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n","  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n","  \"Core environment is written in old step API which returns one bool instead of two. \"\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -9.0\n"]}]},{"metadata":{"id":"qUNldrqa6eeM"},"cell_type":"code","source":[""],"execution_count":null,"outputs":[]},{"metadata":{"id":"3zZTecVWLLes"},"cell_type":"code","source":["def sigmoid(x): \n","  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n","\n","def prepro(I):\n","  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n","  I = I[35:195] # crop\n","  I = I[::2,::2,0] # downsample by factor of 2\n","  I[I == 144] = 0 # erase background (background type 1)\n","  I[I == 109] = 0 # erase background (background type 2)\n","  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n","  return I.astype(np.float).ravel()\n","\n","def policy_forward(x):\n","  h = np.dot(model['W1'], x)\n","  h[h<0] = 0 # ReLU nonlinearity\n","  logp = np.dot(model['W2'], h)\n","  p = sigmoid(logp)\n","  return p, h # return probability of taking action 2, and hidden state\n","\n","def model_step(model, observation, prev_x):\n","  # preprocess the observation, set input to network to be difference image\n","  cur_x = prepro(observation)\n","  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","  prev_x = cur_x\n","  \n","  # forward the policy network and sample an action from the returned probability\n","  aprob, _ = policy_forward(x)\n","  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n","  \n","  return action, prev_x\n","\n","def play_game(env, model):\n","  observation = env.reset()\n","\n","  frames = []\n","  cumulated_reward = 0\n","\n","  prev_x = None # used in computing the difference frame\n","\n","  for t in range(1000):\n","      frames.append(env.render(mode = 'rgb_array'))\n","      action, prev_x = model_step(model, observation, prev_x)\n","      observation, reward, done, info = env.step(action)\n","      cumulated_reward += reward\n","      if done:\n","          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","          break\n","  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","  env.close()\n","  display_frames_as_gif(frames)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"6gWvZQ7AQLQt"},"cell_type":"markdown","source":["## Step 3: Policy Gradient from Scratch"]},{"metadata":{"id":"eqFm7hqcItWl"},"cell_type":"code","source":["import numpy as np\n","\n","# model initialization\n","H = 200 # number of hidden layer neurons\n","D = 80 * 80 # input dimensionality: 80x80 grid\n","model = {}\n","model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n","model['W2'] = np.random.randn(H) / np.sqrt(H)\n","\n","# import pickle\n","# model = pickle.load(open('model.pkl', 'rb'))"],"execution_count":null,"outputs":[]},{"metadata":{"id":"IJ4SeY8tPxvn"},"cell_type":"code","source":[""],"execution_count":null,"outputs":[]},{"metadata":{"id":"TwjiwKisQM19"},"cell_type":"code","source":["# hyperparameters\n","batch_size = 10 # every how many episodes to do a param update?\n","# learning_rate = 1e-4\n","learning_rate = 1e-3\n"," \n","gamma = 0.99 # discount factor for reward\n","decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n","  \n","grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n","rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n","\n","def discount_rewards(r):\n","  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n","  discounted_r = np.zeros_like(r, dtype=np.float32)\n","  running_add = 0\n","  for t in reversed(range(0, r.size)):\n","    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n","    running_add = running_add * gamma + r[t]\n","    discounted_r[t] = running_add\n","  return discounted_r\n","\n","def policy_backward(epx, eph, epdlogp):\n","  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n","  dW2 = np.dot(eph.T, epdlogp).ravel()\n","  dh = np.outer(epdlogp, model['W2'])\n","  dh[eph <= 0] = 0 # backpro prelu\n","  dW1 = np.dot(dh.T, epx)\n","  return {'W1':dW1, 'W2':dW2}\n","\n","def train_model(env, model, total_episodes = 100):\n","  hist = []\n","  observation = env.reset()\n","\n","  prev_x = None # used in computing the difference frame\n","  xs,hs,dlogps,drs = [],[],[],[]\n","  running_reward = None\n","  reward_sum = 0\n","  episode_number = 0\n","\n","  while True:\n","    # preprocess the observation, set input to network to be difference image\n","    cur_x = prepro(observation)\n","    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","    prev_x = cur_x\n","\n","    # forward the policy network and sample an action from the returned probability\n","    aprob, h = policy_forward(x)\n","    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n","\n","    # record various intermediates (needed later for backprop)\n","    xs.append(x) # observation\n","    hs.append(h) # hidden state\n","    y = 1 if action == 2 else 0 # a \"fake label\"\n","    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n","\n","    # step the environment and get new measurements\n","    observation, reward, done, info = env.step(action)\n","    reward_sum += reward\n","\n","    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n","\n","    if done: # an episode finished\n","      episode_number += 1\n","\n","      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n","      epx = np.vstack(xs)\n","      eph = np.vstack(hs)\n","      epdlogp = np.vstack(dlogps)\n","      epr = np.vstack(drs)\n","      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n","\n","      # compute the discounted reward backwards through time\n","      discounted_epr = discount_rewards(epr)\n","      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n","      discounted_epr -= np.mean(discounted_epr)\n","      discounted_epr /= np.std(discounted_epr)\n","\n","      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n","      grad = policy_backward(epx, eph, epdlogp)\n","      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n","\n","      # perform rmsprop parameter update every batch_size episodes\n","      if episode_number % batch_size == 0:\n","        for k,v in model.items():\n","          g = grad_buffer[k] # gradient\n","          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n","          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n","          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n","\n","      # boring book-keeping\n","      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n","      hist.append((episode_number, reward_sum, running_reward))\n","      plt.scatter(episode_number, running_reward, marker=\".\")\n","      print ('resetting env. episode %f, reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n","\n","      reward_sum = 0\n","      observation = env.reset() # reset env\n","      prev_x = None\n","      if episode_number == total_episodes or running_reward >= -10: \n","        return hist\n","        return plt.show()\n","\n","  #   if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n","  #     print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"],"execution_count":null,"outputs":[]},{"metadata":{"id":"G6Ka_5Vl9Orm","outputId":"6f38548e-3448-4e1b-dce3-2135bf25a78e","colab":{"base_uri":"https://localhost:8080/"}},"cell_type":"code","source":["%time hist1 = train_model(env, model, total_episodes=4000)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 2.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 3.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 4.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 5.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 6.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 7.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 8.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 9.000000, reward total was -20.000000. running mean: -20.990000\n","resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.990100\n","resetting env. episode 11.000000, reward total was -21.000000. running mean: -20.990199\n","resetting env. episode 12.000000, reward total was -20.000000. running mean: -20.980297\n","resetting env. episode 13.000000, reward total was -21.000000. running mean: -20.980494\n","resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.980689\n","resetting env. episode 15.000000, reward total was -17.000000. running mean: -20.940882\n","resetting env. episode 16.000000, reward total was -20.000000. running mean: -20.931473\n","resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.932159\n","resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.932837\n","resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.933509\n","resetting env. episode 20.000000, reward total was -20.000000. running mean: -20.924174\n","resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.924932\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.925683\n","resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.926426\n","resetting env. episode 24.000000, reward total was -19.000000. running mean: -20.907161\n","resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.908090\n","resetting env. episode 26.000000, reward total was -20.000000. running mean: -20.899009\n","resetting env. episode 27.000000, reward total was -20.000000. running mean: -20.890019\n","resetting env. episode 28.000000, reward total was -19.000000. running mean: -20.871119\n","resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.872407\n","resetting env. episode 30.000000, reward total was -19.000000. running mean: -20.853683\n","resetting env. episode 31.000000, reward total was -20.000000. running mean: -20.845147\n","resetting env. episode 32.000000, reward total was -19.000000. running mean: -20.826695\n","resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.828428\n","resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.830144\n","resetting env. episode 35.000000, reward total was -20.000000. running mean: -20.821842\n","resetting env. episode 36.000000, reward total was -19.000000. running mean: -20.803624\n","resetting env. episode 37.000000, reward total was -18.000000. running mean: -20.775588\n","resetting env. episode 38.000000, reward total was -16.000000. running mean: -20.727832\n","resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.730554\n","resetting env. episode 40.000000, reward total was -20.000000. running mean: -20.723248\n","resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.726016\n","resetting env. episode 42.000000, reward total was -21.000000. running mean: -20.728755\n","resetting env. episode 43.000000, reward total was -18.000000. running mean: -20.701468\n","resetting env. episode 44.000000, reward total was -21.000000. running mean: -20.704453\n","resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.707409\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.710335\n","resetting env. episode 47.000000, reward total was -18.000000. running mean: -20.683231\n","resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.686399\n","resetting env. episode 49.000000, reward total was -21.000000. running mean: -20.689535\n","resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.692640\n","resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.695713\n","resetting env. episode 52.000000, reward total was -20.000000. running mean: -20.688756\n","resetting env. episode 53.000000, reward total was -20.000000. running mean: -20.681868\n","resetting env. episode 54.000000, reward total was -17.000000. running mean: -20.645050\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.648599\n","resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.652113\n","resetting env. episode 57.000000, reward total was -20.000000. running mean: -20.645592\n","resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.649136\n","resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.652645\n","resetting env. episode 60.000000, reward total was -19.000000. running mean: -20.636118\n","resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.639757\n","resetting env. episode 62.000000, reward total was -21.000000. running mean: -20.643360\n","resetting env. episode 63.000000, reward total was -19.000000. running mean: -20.626926\n","resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.630657\n","resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.634350\n","resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.638007\n","resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.641627\n","resetting env. episode 68.000000, reward total was -20.000000. running mean: -20.635210\n","resetting env. episode 69.000000, reward total was -21.000000. running mean: -20.638858\n","resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.642470\n","resetting env. episode 71.000000, reward total was -21.000000. running mean: -20.646045\n","resetting env. episode 72.000000, reward total was -20.000000. running mean: -20.639585\n","resetting env. episode 73.000000, reward total was -20.000000. running mean: -20.633189\n","resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.636857\n","resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.640488\n","resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.644083\n","resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.647643\n","resetting env. episode 78.000000, reward total was -21.000000. running mean: -20.651166\n","resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.654654\n","resetting env. episode 80.000000, reward total was -21.000000. running mean: -20.658108\n","resetting env. episode 81.000000, reward total was -20.000000. running mean: -20.651527\n","resetting env. episode 82.000000, reward total was -19.000000. running mean: -20.635012\n","resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.638661\n","resetting env. episode 84.000000, reward total was -21.000000. running mean: -20.642275\n","resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.645852\n","resetting env. episode 86.000000, reward total was -20.000000. running mean: -20.639394\n","resetting env. episode 87.000000, reward total was -20.000000. running mean: -20.633000\n","resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.636670\n","resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.640303\n","resetting env. episode 90.000000, reward total was -20.000000. running mean: -20.633900\n","resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.637561\n","resetting env. episode 92.000000, reward total was -21.000000. running mean: -20.641185\n","resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.644773\n","resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.648326\n","resetting env. episode 95.000000, reward total was -21.000000. running mean: -20.651842\n","resetting env. episode 96.000000, reward total was -20.000000. running mean: -20.645324\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.648871\n","resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.652382\n","resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.655858\n","resetting env. episode 100.000000, reward total was -20.000000. running mean: -20.649300\n","resetting env. episode 101.000000, reward total was -21.000000. running mean: -20.652807\n","resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.656279\n","resetting env. episode 103.000000, reward total was -20.000000. running mean: -20.649716\n","resetting env. episode 104.000000, reward total was -20.000000. running mean: -20.643219\n","resetting env. episode 105.000000, reward total was -20.000000. running mean: -20.636786\n","resetting env. episode 106.000000, reward total was -20.000000. running mean: -20.630419\n","resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.634114\n","resetting env. episode 108.000000, reward total was -20.000000. running mean: -20.627773\n","resetting env. episode 109.000000, reward total was -20.000000. running mean: -20.621496\n","resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.625281\n","resetting env. episode 111.000000, reward total was -19.000000. running mean: -20.609028\n","resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.612938\n","resetting env. episode 113.000000, reward total was -19.000000. running mean: -20.596808\n","resetting env. episode 114.000000, reward total was -20.000000. running mean: -20.590840\n","resetting env. episode 115.000000, reward total was -20.000000. running mean: -20.584932\n","resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.589082\n","resetting env. episode 117.000000, reward total was -20.000000. running mean: -20.583192\n","resetting env. episode 118.000000, reward total was -20.000000. running mean: -20.577360\n","resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.581586\n","resetting env. episode 120.000000, reward total was -20.000000. running mean: -20.575770\n","resetting env. episode 121.000000, reward total was -20.000000. running mean: -20.570012\n","resetting env. episode 122.000000, reward total was -21.000000. running mean: -20.574312\n","resetting env. episode 123.000000, reward total was -19.000000. running mean: -20.558569\n","resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.562984\n","resetting env. episode 125.000000, reward total was -20.000000. running mean: -20.557354\n","resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.561780\n","resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.566162\n","resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.570501\n","resetting env. episode 129.000000, reward total was -20.000000. running mean: -20.564796\n","resetting env. episode 130.000000, reward total was -18.000000. running mean: -20.539148\n","resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.543756\n","resetting env. episode 132.000000, reward total was -20.000000. running mean: -20.538319\n","resetting env. episode 133.000000, reward total was -20.000000. running mean: -20.532936\n","resetting env. episode 134.000000, reward total was -20.000000. running mean: -20.527606\n","resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.532330\n","resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.537007\n","resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.541637\n","resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.546220\n","resetting env. episode 139.000000, reward total was -20.000000. running mean: -20.540758\n","resetting env. episode 140.000000, reward total was -20.000000. running mean: -20.535351\n","resetting env. episode 141.000000, reward total was -17.000000. running mean: -20.499997\n","resetting env. episode 142.000000, reward total was -17.000000. running mean: -20.464997\n","resetting env. episode 143.000000, reward total was -19.000000. running mean: -20.450347\n","resetting env. episode 144.000000, reward total was -21.000000. running mean: -20.455844\n","resetting env. episode 145.000000, reward total was -20.000000. running mean: -20.451285\n","resetting env. episode 146.000000, reward total was -18.000000. running mean: -20.426772\n","resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.432505\n","resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.438180\n","resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.443798\n","resetting env. episode 150.000000, reward total was -21.000000. running mean: -20.449360\n","resetting env. episode 151.000000, reward total was -19.000000. running mean: -20.434866\n","resetting env. episode 152.000000, reward total was -21.000000. running mean: -20.440518\n","resetting env. episode 153.000000, reward total was -19.000000. running mean: -20.426112\n","resetting env. episode 154.000000, reward total was -19.000000. running mean: -20.411851\n","resetting env. episode 155.000000, reward total was -18.000000. running mean: -20.387733\n","resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.393855\n","resetting env. episode 157.000000, reward total was -21.000000. running mean: -20.399917\n","resetting env. episode 158.000000, reward total was -21.000000. running mean: -20.405918\n","resetting env. episode 159.000000, reward total was -20.000000. running mean: -20.401859\n","resetting env. episode 160.000000, reward total was -20.000000. running mean: -20.397840\n","resetting env. episode 161.000000, reward total was -20.000000. running mean: -20.393862\n","resetting env. episode 162.000000, reward total was -20.000000. running mean: -20.389923\n","resetting env. episode 163.000000, reward total was -19.000000. running mean: -20.376024\n","resetting env. episode 164.000000, reward total was -20.000000. running mean: -20.372263\n","resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.378541\n","resetting env. episode 166.000000, reward total was -17.000000. running mean: -20.344755\n","resetting env. episode 167.000000, reward total was -20.000000. running mean: -20.341308\n","resetting env. episode 168.000000, reward total was -17.000000. running mean: -20.307895\n","resetting env. episode 169.000000, reward total was -20.000000. running mean: -20.304816\n","resetting env. episode 170.000000, reward total was -19.000000. running mean: -20.291768\n","resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.298850\n","resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.305862\n","resetting env. episode 173.000000, reward total was -19.000000. running mean: -20.292803\n","resetting env. episode 174.000000, reward total was -20.000000. running mean: -20.289875\n","resetting env. episode 175.000000, reward total was -18.000000. running mean: -20.266976\n","resetting env. episode 176.000000, reward total was -20.000000. running mean: -20.264306\n","resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.271663\n","resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.278947\n","resetting env. episode 179.000000, reward total was -20.000000. running mean: -20.276157\n","resetting env. episode 180.000000, reward total was -17.000000. running mean: -20.243396\n","resetting env. episode 181.000000, reward total was -20.000000. running mean: -20.240962\n","resetting env. episode 182.000000, reward total was -17.000000. running mean: -20.208552\n","resetting env. episode 183.000000, reward total was -19.000000. running mean: -20.196467\n","resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.204502\n","resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.212457\n","resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.220332\n","resetting env. episode 187.000000, reward total was -20.000000. running mean: -20.218129\n","resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.225948\n","resetting env. episode 189.000000, reward total was -19.000000. running mean: -20.213688\n","resetting env. episode 190.000000, reward total was -20.000000. running mean: -20.211551\n","resetting env. episode 191.000000, reward total was -20.000000. running mean: -20.209436\n","resetting env. episode 192.000000, reward total was -18.000000. running mean: -20.187341\n","resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.195468\n","resetting env. episode 194.000000, reward total was -18.000000. running mean: -20.173513\n","resetting env. episode 195.000000, reward total was -20.000000. running mean: -20.171778\n","resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.180060\n","resetting env. episode 197.000000, reward total was -19.000000. running mean: -20.168260\n","resetting env. episode 198.000000, reward total was -19.000000. running mean: -20.156577\n","resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.165011\n","resetting env. episode 200.000000, reward total was -20.000000. running mean: -20.163361\n","resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.171728\n","resetting env. episode 202.000000, reward total was -20.000000. running mean: -20.170010\n","resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.178310\n","resetting env. episode 204.000000, reward total was -19.000000. running mean: -20.166527\n","resetting env. episode 205.000000, reward total was -19.000000. running mean: -20.154862\n","resetting env. episode 206.000000, reward total was -19.000000. running mean: -20.143313\n","resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.151880\n","resetting env. episode 208.000000, reward total was -20.000000. running mean: -20.150361\n","resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.158858\n","resetting env. episode 210.000000, reward total was -20.000000. running mean: -20.157269\n","resetting env. episode 211.000000, reward total was -19.000000. running mean: -20.145697\n","resetting env. episode 212.000000, reward total was -20.000000. running mean: -20.144240\n","resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.152797\n","resetting env. episode 214.000000, reward total was -19.000000. running mean: -20.141269\n","resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.149857\n","resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.158358\n","resetting env. episode 217.000000, reward total was -17.000000. running mean: -20.126774\n","resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.135507\n","resetting env. episode 219.000000, reward total was -20.000000. running mean: -20.134152\n","resetting env. episode 220.000000, reward total was -20.000000. running mean: -20.132810\n","resetting env. episode 221.000000, reward total was -19.000000. running mean: -20.121482\n","resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.130267\n","resetting env. episode 223.000000, reward total was -19.000000. running mean: -20.118964\n","resetting env. episode 224.000000, reward total was -20.000000. running mean: -20.117775\n","resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.126597\n","resetting env. episode 226.000000, reward total was -19.000000. running mean: -20.115331\n","resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.124178\n","resetting env. episode 228.000000, reward total was -20.000000. running mean: -20.122936\n","resetting env. episode 229.000000, reward total was -20.000000. running mean: -20.121707\n","resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.130490\n","resetting env. episode 231.000000, reward total was -19.000000. running mean: -20.119185\n","resetting env. episode 232.000000, reward total was -20.000000. running mean: -20.117993\n","resetting env. episode 233.000000, reward total was -20.000000. running mean: -20.116813\n","resetting env. episode 234.000000, reward total was -19.000000. running mean: -20.105645\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.114588\n","resetting env. episode 236.000000, reward total was -18.000000. running mean: -20.093442\n","resetting env. episode 237.000000, reward total was -18.000000. running mean: -20.072508\n","resetting env. episode 238.000000, reward total was -20.000000. running mean: -20.071783\n","resetting env. episode 239.000000, reward total was -20.000000. running mean: -20.071065\n","resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.080354\n","resetting env. episode 241.000000, reward total was -20.000000. running mean: -20.079551\n","resetting env. episode 242.000000, reward total was -20.000000. running mean: -20.078755\n","resetting env. episode 243.000000, reward total was -20.000000. running mean: -20.077968\n","resetting env. episode 244.000000, reward total was -18.000000. running mean: -20.057188\n","resetting env. episode 245.000000, reward total was -18.000000. running mean: -20.036616\n","resetting env. episode 246.000000, reward total was -19.000000. running mean: -20.026250\n","resetting env. episode 247.000000, reward total was -21.000000. running mean: -20.035988\n","resetting env. episode 248.000000, reward total was -20.000000. running mean: -20.035628\n","resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.045271\n","resetting env. episode 250.000000, reward total was -20.000000. running mean: -20.044819\n","resetting env. episode 251.000000, reward total was -20.000000. running mean: -20.044371\n","resetting env. episode 252.000000, reward total was -20.000000. running mean: -20.043927\n","resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.053488\n","resetting env. episode 254.000000, reward total was -20.000000. running mean: -20.052953\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.062423\n","resetting env. episode 256.000000, reward total was -19.000000. running mean: -20.051799\n","resetting env. episode 257.000000, reward total was -17.000000. running mean: -20.021281\n","resetting env. episode 258.000000, reward total was -19.000000. running mean: -20.011068\n","resetting env. episode 259.000000, reward total was -20.000000. running mean: -20.010957\n","resetting env. episode 260.000000, reward total was -19.000000. running mean: -20.000848\n","resetting env. episode 261.000000, reward total was -19.000000. running mean: -19.990839\n","resetting env. episode 262.000000, reward total was -20.000000. running mean: -19.990931\n","resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.001022\n","resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.011011\n","resetting env. episode 265.000000, reward total was -20.000000. running mean: -20.010901\n","resetting env. episode 266.000000, reward total was -21.000000. running mean: -20.020792\n","resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.030584\n","resetting env. episode 268.000000, reward total was -20.000000. running mean: -20.030279\n","resetting env. episode 269.000000, reward total was -20.000000. running mean: -20.029976\n","resetting env. episode 270.000000, reward total was -21.000000. running mean: -20.039676\n","resetting env. episode 271.000000, reward total was -19.000000. running mean: -20.029279\n","resetting env. episode 272.000000, reward total was -20.000000. running mean: -20.028987\n","resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.038697\n","resetting env. episode 274.000000, reward total was -19.000000. running mean: -20.028310\n","resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.038027\n","resetting env. episode 276.000000, reward total was -19.000000. running mean: -20.027646\n","resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.037370\n","resetting env. episode 278.000000, reward total was -18.000000. running mean: -20.016996\n","resetting env. episode 279.000000, reward total was -17.000000. running mean: -19.986826\n","resetting env. episode 280.000000, reward total was -19.000000. running mean: -19.976958\n","resetting env. episode 281.000000, reward total was -19.000000. running mean: -19.967188\n","resetting env. episode 282.000000, reward total was -21.000000. running mean: -19.977516\n","resetting env. episode 283.000000, reward total was -15.000000. running mean: -19.927741\n","resetting env. episode 284.000000, reward total was -21.000000. running mean: -19.938464\n","resetting env. episode 285.000000, reward total was -21.000000. running mean: -19.949079\n","resetting env. episode 286.000000, reward total was -21.000000. running mean: -19.959588\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -19.969993\n","resetting env. episode 288.000000, reward total was -20.000000. running mean: -19.970293\n","resetting env. episode 289.000000, reward total was -20.000000. running mean: -19.970590\n","resetting env. episode 290.000000, reward total was -17.000000. running mean: -19.940884\n","resetting env. episode 291.000000, reward total was -18.000000. running mean: -19.921475\n","resetting env. episode 292.000000, reward total was -20.000000. running mean: -19.922260\n","resetting env. episode 293.000000, reward total was -20.000000. running mean: -19.923038\n","resetting env. episode 294.000000, reward total was -17.000000. running mean: -19.893807\n","resetting env. episode 295.000000, reward total was -19.000000. running mean: -19.884869\n","resetting env. episode 296.000000, reward total was -18.000000. running mean: -19.866020\n","resetting env. episode 297.000000, reward total was -19.000000. running mean: -19.857360\n","resetting env. episode 298.000000, reward total was -21.000000. running mean: -19.868787\n","resetting env. episode 299.000000, reward total was -19.000000. running mean: -19.860099\n","resetting env. episode 300.000000, reward total was -18.000000. running mean: -19.841498\n","resetting env. episode 301.000000, reward total was -18.000000. running mean: -19.823083\n","resetting env. episode 302.000000, reward total was -20.000000. running mean: -19.824852\n","resetting env. episode 303.000000, reward total was -21.000000. running mean: -19.836603\n","resetting env. episode 304.000000, reward total was -19.000000. running mean: -19.828237\n","resetting env. episode 305.000000, reward total was -21.000000. running mean: -19.839955\n","resetting env. episode 306.000000, reward total was -20.000000. running mean: -19.841556\n","resetting env. episode 307.000000, reward total was -18.000000. running mean: -19.823140\n","resetting env. episode 308.000000, reward total was -20.000000. running mean: -19.824909\n","resetting env. episode 309.000000, reward total was -21.000000. running mean: -19.836659\n","resetting env. episode 310.000000, reward total was -21.000000. running mean: -19.848293\n","resetting env. episode 311.000000, reward total was -20.000000. running mean: -19.849810\n","resetting env. episode 312.000000, reward total was -18.000000. running mean: -19.831312\n","resetting env. episode 313.000000, reward total was -19.000000. running mean: -19.822999\n","resetting env. episode 314.000000, reward total was -21.000000. running mean: -19.834769\n","resetting env. episode 315.000000, reward total was -19.000000. running mean: -19.826421\n","resetting env. episode 316.000000, reward total was -19.000000. running mean: -19.818157\n","resetting env. episode 317.000000, reward total was -21.000000. running mean: -19.829975\n","resetting env. episode 318.000000, reward total was -20.000000. running mean: -19.831676\n","resetting env. episode 319.000000, reward total was -20.000000. running mean: -19.833359\n","resetting env. episode 320.000000, reward total was -21.000000. running mean: -19.845025\n","resetting env. episode 321.000000, reward total was -18.000000. running mean: -19.826575\n","resetting env. episode 322.000000, reward total was -16.000000. running mean: -19.788309\n","resetting env. episode 323.000000, reward total was -17.000000. running mean: -19.760426\n","resetting env. episode 324.000000, reward total was -21.000000. running mean: -19.772822\n","resetting env. episode 325.000000, reward total was -21.000000. running mean: -19.785094\n","resetting env. episode 326.000000, reward total was -20.000000. running mean: -19.787243\n","resetting env. episode 327.000000, reward total was -21.000000. running mean: -19.799370\n","resetting env. episode 328.000000, reward total was -16.000000. running mean: -19.761377\n","resetting env. episode 329.000000, reward total was -17.000000. running mean: -19.733763\n","resetting env. episode 330.000000, reward total was -19.000000. running mean: -19.726425\n","resetting env. episode 331.000000, reward total was -19.000000. running mean: -19.719161\n","resetting env. episode 332.000000, reward total was -21.000000. running mean: -19.731969\n","resetting env. episode 333.000000, reward total was -19.000000. running mean: -19.724650\n","resetting env. episode 334.000000, reward total was -21.000000. running mean: -19.737403\n","resetting env. episode 335.000000, reward total was -19.000000. running mean: -19.730029\n","resetting env. episode 336.000000, reward total was -21.000000. running mean: -19.742729\n","resetting env. episode 337.000000, reward total was -20.000000. running mean: -19.745302\n","resetting env. episode 338.000000, reward total was -21.000000. running mean: -19.757848\n","resetting env. episode 339.000000, reward total was -19.000000. running mean: -19.750270\n","resetting env. episode 340.000000, reward total was -19.000000. running mean: -19.742767\n","resetting env. episode 341.000000, reward total was -20.000000. running mean: -19.745340\n","resetting env. episode 342.000000, reward total was -20.000000. running mean: -19.747886\n","resetting env. episode 343.000000, reward total was -19.000000. running mean: -19.740407\n","resetting env. episode 344.000000, reward total was -19.000000. running mean: -19.733003\n","resetting env. episode 345.000000, reward total was -19.000000. running mean: -19.725673\n","resetting env. episode 346.000000, reward total was -20.000000. running mean: -19.728417\n","resetting env. episode 347.000000, reward total was -21.000000. running mean: -19.741132\n","resetting env. episode 348.000000, reward total was -19.000000. running mean: -19.733721\n","resetting env. episode 349.000000, reward total was -17.000000. running mean: -19.706384\n","resetting env. episode 350.000000, reward total was -20.000000. running mean: -19.709320\n","resetting env. episode 351.000000, reward total was -21.000000. running mean: -19.722227\n","resetting env. episode 352.000000, reward total was -19.000000. running mean: -19.715005\n","resetting env. episode 353.000000, reward total was -16.000000. running mean: -19.677854\n","resetting env. episode 354.000000, reward total was -19.000000. running mean: -19.671076\n","resetting env. episode 355.000000, reward total was -21.000000. running mean: -19.684365\n","resetting env. episode 356.000000, reward total was -19.000000. running mean: -19.677522\n","resetting env. episode 357.000000, reward total was -19.000000. running mean: -19.670746\n","resetting env. episode 358.000000, reward total was -21.000000. running mean: -19.684039\n","resetting env. episode 359.000000, reward total was -19.000000. running mean: -19.677198\n","resetting env. episode 360.000000, reward total was -21.000000. running mean: -19.690426\n","resetting env. episode 361.000000, reward total was -15.000000. running mean: -19.643522\n","resetting env. episode 362.000000, reward total was -21.000000. running mean: -19.657087\n","resetting env. episode 363.000000, reward total was -18.000000. running mean: -19.640516\n","resetting env. episode 364.000000, reward total was -20.000000. running mean: -19.644111\n","resetting env. episode 365.000000, reward total was -17.000000. running mean: -19.617670\n","resetting env. episode 366.000000, reward total was -21.000000. running mean: -19.631493\n","resetting env. episode 367.000000, reward total was -20.000000. running mean: -19.635178\n","resetting env. episode 368.000000, reward total was -21.000000. running mean: -19.648826\n","resetting env. episode 369.000000, reward total was -21.000000. running mean: -19.662338\n","resetting env. episode 370.000000, reward total was -21.000000. running mean: -19.675715\n","resetting env. episode 371.000000, reward total was -19.000000. running mean: -19.668958\n","resetting env. episode 372.000000, reward total was -21.000000. running mean: -19.682268\n","resetting env. episode 373.000000, reward total was -20.000000. running mean: -19.685445\n","resetting env. episode 374.000000, reward total was -19.000000. running mean: -19.678591\n","resetting env. episode 375.000000, reward total was -21.000000. running mean: -19.691805\n","resetting env. episode 376.000000, reward total was -18.000000. running mean: -19.674887\n","resetting env. episode 377.000000, reward total was -17.000000. running mean: -19.648138\n","resetting env. episode 378.000000, reward total was -19.000000. running mean: -19.641657\n","resetting env. episode 379.000000, reward total was -17.000000. running mean: -19.615240\n","resetting env. episode 380.000000, reward total was -19.000000. running mean: -19.609088\n","resetting env. episode 381.000000, reward total was -21.000000. running mean: -19.622997\n","resetting env. episode 382.000000, reward total was -18.000000. running mean: -19.606767\n","resetting env. episode 383.000000, reward total was -21.000000. running mean: -19.620699\n","resetting env. episode 384.000000, reward total was -20.000000. running mean: -19.624492\n","resetting env. episode 385.000000, reward total was -18.000000. running mean: -19.608247\n","resetting env. episode 386.000000, reward total was -20.000000. running mean: -19.612165\n","resetting env. episode 387.000000, reward total was -21.000000. running mean: -19.626043\n","resetting env. episode 388.000000, reward total was -18.000000. running mean: -19.609783\n","resetting env. episode 389.000000, reward total was -20.000000. running mean: -19.613685\n","resetting env. episode 390.000000, reward total was -17.000000. running mean: -19.587548\n","resetting env. episode 391.000000, reward total was -19.000000. running mean: -19.581673\n","resetting env. episode 392.000000, reward total was -21.000000. running mean: -19.595856\n","resetting env. episode 393.000000, reward total was -20.000000. running mean: -19.599897\n","resetting env. episode 394.000000, reward total was -20.000000. running mean: -19.603898\n","resetting env. episode 395.000000, reward total was -20.000000. running mean: -19.607859\n","resetting env. episode 396.000000, reward total was -20.000000. running mean: -19.611781\n","resetting env. episode 397.000000, reward total was -19.000000. running mean: -19.605663\n","resetting env. episode 398.000000, reward total was -21.000000. running mean: -19.619606\n","resetting env. episode 399.000000, reward total was -19.000000. running mean: -19.613410\n","resetting env. episode 400.000000, reward total was -20.000000. running mean: -19.617276\n","resetting env. episode 401.000000, reward total was -18.000000. running mean: -19.601103\n","resetting env. episode 402.000000, reward total was -20.000000. running mean: -19.605092\n","resetting env. episode 403.000000, reward total was -18.000000. running mean: -19.589041\n","resetting env. episode 404.000000, reward total was -21.000000. running mean: -19.603151\n","resetting env. episode 405.000000, reward total was -19.000000. running mean: -19.597120\n","resetting env. episode 406.000000, reward total was -20.000000. running mean: -19.601148\n","resetting env. episode 407.000000, reward total was -19.000000. running mean: -19.595137\n","resetting env. episode 408.000000, reward total was -18.000000. running mean: -19.579185\n","resetting env. episode 409.000000, reward total was -21.000000. running mean: -19.593394\n","resetting env. episode 410.000000, reward total was -18.000000. running mean: -19.577460\n","resetting env. episode 411.000000, reward total was -21.000000. running mean: -19.591685\n","resetting env. episode 412.000000, reward total was -21.000000. running mean: -19.605768\n","resetting env. episode 413.000000, reward total was -21.000000. running mean: -19.619711\n","resetting env. episode 414.000000, reward total was -21.000000. running mean: -19.633513\n","resetting env. episode 415.000000, reward total was -19.000000. running mean: -19.627178\n","resetting env. episode 416.000000, reward total was -19.000000. running mean: -19.620907\n","resetting env. episode 417.000000, reward total was -19.000000. running mean: -19.614697\n","resetting env. episode 418.000000, reward total was -21.000000. running mean: -19.628550\n","resetting env. episode 419.000000, reward total was -19.000000. running mean: -19.622265\n","resetting env. episode 420.000000, reward total was -18.000000. running mean: -19.606042\n","resetting env. episode 421.000000, reward total was -18.000000. running mean: -19.589982\n","resetting env. episode 422.000000, reward total was -20.000000. running mean: -19.594082\n","resetting env. episode 423.000000, reward total was -19.000000. running mean: -19.588141\n","resetting env. episode 424.000000, reward total was -19.000000. running mean: -19.582260\n","resetting env. episode 425.000000, reward total was -20.000000. running mean: -19.586437\n","resetting env. episode 426.000000, reward total was -21.000000. running mean: -19.600573\n","resetting env. episode 427.000000, reward total was -19.000000. running mean: -19.594567\n","resetting env. episode 428.000000, reward total was -21.000000. running mean: -19.608621\n","resetting env. episode 429.000000, reward total was -19.000000. running mean: -19.602535\n","resetting env. episode 430.000000, reward total was -20.000000. running mean: -19.606510\n","resetting env. episode 431.000000, reward total was -17.000000. running mean: -19.580445\n","resetting env. episode 432.000000, reward total was -17.000000. running mean: -19.554640\n","resetting env. episode 433.000000, reward total was -21.000000. running mean: -19.569094\n","resetting env. episode 434.000000, reward total was -21.000000. running mean: -19.583403\n","resetting env. episode 435.000000, reward total was -19.000000. running mean: -19.577569\n","resetting env. episode 436.000000, reward total was -17.000000. running mean: -19.551793\n","resetting env. episode 437.000000, reward total was -21.000000. running mean: -19.566275\n","resetting env. episode 438.000000, reward total was -20.000000. running mean: -19.570613\n","resetting env. episode 439.000000, reward total was -19.000000. running mean: -19.564907\n","resetting env. episode 440.000000, reward total was -21.000000. running mean: -19.579257\n","resetting env. episode 441.000000, reward total was -19.000000. running mean: -19.573465\n","resetting env. episode 442.000000, reward total was -21.000000. running mean: -19.587730\n","resetting env. episode 443.000000, reward total was -19.000000. running mean: -19.581853\n","resetting env. episode 444.000000, reward total was -17.000000. running mean: -19.556034\n","resetting env. episode 445.000000, reward total was -21.000000. running mean: -19.570474\n","resetting env. episode 446.000000, reward total was -19.000000. running mean: -19.564769\n","resetting env. episode 447.000000, reward total was -20.000000. running mean: -19.569122\n","resetting env. episode 448.000000, reward total was -20.000000. running mean: -19.573430\n","resetting env. episode 449.000000, reward total was -18.000000. running mean: -19.557696\n","resetting env. episode 450.000000, reward total was -20.000000. running mean: -19.562119\n","resetting env. episode 451.000000, reward total was -20.000000. running mean: -19.566498\n","resetting env. episode 452.000000, reward total was -21.000000. running mean: -19.580833\n","resetting env. episode 453.000000, reward total was -21.000000. running mean: -19.595025\n","resetting env. episode 454.000000, reward total was -21.000000. running mean: -19.609074\n","resetting env. episode 455.000000, reward total was -20.000000. running mean: -19.612984\n","resetting env. episode 456.000000, reward total was -20.000000. running mean: -19.616854\n","resetting env. episode 457.000000, reward total was -19.000000. running mean: -19.610685\n","resetting env. episode 458.000000, reward total was -19.000000. running mean: -19.604578\n","resetting env. episode 459.000000, reward total was -19.000000. running mean: -19.598533\n","resetting env. episode 460.000000, reward total was -18.000000. running mean: -19.582547\n","resetting env. episode 461.000000, reward total was -19.000000. running mean: -19.576722\n","resetting env. episode 462.000000, reward total was -20.000000. running mean: -19.580955\n","resetting env. episode 463.000000, reward total was -18.000000. running mean: -19.565145\n","resetting env. episode 464.000000, reward total was -21.000000. running mean: -19.579494\n","resetting env. episode 465.000000, reward total was -19.000000. running mean: -19.573699\n","resetting env. episode 466.000000, reward total was -19.000000. running mean: -19.567962\n","resetting env. episode 467.000000, reward total was -20.000000. running mean: -19.572282\n","resetting env. episode 468.000000, reward total was -21.000000. running mean: -19.586559\n","resetting env. episode 469.000000, reward total was -21.000000. running mean: -19.600694\n","resetting env. episode 470.000000, reward total was -20.000000. running mean: -19.604687\n","resetting env. episode 471.000000, reward total was -16.000000. running mean: -19.568640\n","resetting env. episode 472.000000, reward total was -20.000000. running mean: -19.572953\n","resetting env. episode 473.000000, reward total was -19.000000. running mean: -19.567224\n","resetting env. episode 474.000000, reward total was -17.000000. running mean: -19.541552\n","resetting env. episode 475.000000, reward total was -19.000000. running mean: -19.536136\n","resetting env. episode 476.000000, reward total was -21.000000. running mean: -19.550775\n","resetting env. episode 477.000000, reward total was -18.000000. running mean: -19.535267\n","resetting env. episode 478.000000, reward total was -17.000000. running mean: -19.509914\n","resetting env. episode 479.000000, reward total was -15.000000. running mean: -19.464815\n","resetting env. episode 480.000000, reward total was -17.000000. running mean: -19.440167\n","resetting env. episode 481.000000, reward total was -21.000000. running mean: -19.455765\n","resetting env. episode 482.000000, reward total was -16.000000. running mean: -19.421208\n","resetting env. episode 483.000000, reward total was -18.000000. running mean: -19.406996\n","resetting env. episode 484.000000, reward total was -20.000000. running mean: -19.412926\n","resetting env. episode 485.000000, reward total was -19.000000. running mean: -19.408796\n","resetting env. episode 486.000000, reward total was -18.000000. running mean: -19.394709\n","resetting env. episode 487.000000, reward total was -17.000000. running mean: -19.370761\n","resetting env. episode 488.000000, reward total was -20.000000. running mean: -19.377054\n","resetting env. episode 489.000000, reward total was -20.000000. running mean: -19.383283\n","resetting env. episode 490.000000, reward total was -21.000000. running mean: -19.399450\n","resetting env. episode 491.000000, reward total was -21.000000. running mean: -19.415456\n","resetting env. episode 492.000000, reward total was -17.000000. running mean: -19.391301\n","resetting env. episode 493.000000, reward total was -19.000000. running mean: -19.387388\n","resetting env. episode 494.000000, reward total was -19.000000. running mean: -19.383514\n","resetting env. episode 495.000000, reward total was -21.000000. running mean: -19.399679\n","resetting env. episode 496.000000, reward total was -21.000000. running mean: -19.415683\n","resetting env. episode 497.000000, reward total was -21.000000. running mean: -19.431526\n","resetting env. episode 498.000000, reward total was -20.000000. running mean: -19.437210\n","resetting env. episode 499.000000, reward total was -21.000000. running mean: -19.452838\n","resetting env. episode 500.000000, reward total was -19.000000. running mean: -19.448310\n","resetting env. episode 501.000000, reward total was -21.000000. running mean: -19.463827\n","resetting env. episode 502.000000, reward total was -19.000000. running mean: -19.459189\n","resetting env. episode 503.000000, reward total was -19.000000. running mean: -19.454597\n","resetting env. episode 504.000000, reward total was -20.000000. running mean: -19.460051\n","resetting env. episode 505.000000, reward total was -18.000000. running mean: -19.445450\n","resetting env. episode 506.000000, reward total was -20.000000. running mean: -19.450996\n","resetting env. episode 507.000000, reward total was -20.000000. running mean: -19.456486\n","resetting env. episode 508.000000, reward total was -17.000000. running mean: -19.431921\n","resetting env. episode 509.000000, reward total was -17.000000. running mean: -19.407602\n","resetting env. episode 510.000000, reward total was -20.000000. running mean: -19.413526\n","resetting env. episode 511.000000, reward total was -19.000000. running mean: -19.409390\n","resetting env. episode 512.000000, reward total was -21.000000. running mean: -19.425297\n","resetting env. episode 513.000000, reward total was -18.000000. running mean: -19.411044\n","resetting env. episode 514.000000, reward total was -19.000000. running mean: -19.406933\n","resetting env. episode 515.000000, reward total was -20.000000. running mean: -19.412864\n","resetting env. episode 516.000000, reward total was -20.000000. running mean: -19.418735\n","resetting env. episode 517.000000, reward total was -18.000000. running mean: -19.404548\n","resetting env. episode 518.000000, reward total was -18.000000. running mean: -19.390502\n","resetting env. episode 519.000000, reward total was -20.000000. running mean: -19.396597\n","resetting env. episode 520.000000, reward total was -20.000000. running mean: -19.402631\n","resetting env. episode 521.000000, reward total was -21.000000. running mean: -19.418605\n","resetting env. episode 522.000000, reward total was -18.000000. running mean: -19.404419\n","resetting env. episode 523.000000, reward total was -21.000000. running mean: -19.420375\n","resetting env. episode 524.000000, reward total was -18.000000. running mean: -19.406171\n","resetting env. episode 525.000000, reward total was -20.000000. running mean: -19.412109\n","resetting env. episode 526.000000, reward total was -18.000000. running mean: -19.397988\n","resetting env. episode 527.000000, reward total was -20.000000. running mean: -19.404008\n","resetting env. episode 528.000000, reward total was -19.000000. running mean: -19.399968\n","resetting env. episode 529.000000, reward total was -16.000000. running mean: -19.365969\n","resetting env. episode 530.000000, reward total was -18.000000. running mean: -19.352309\n","resetting env. episode 531.000000, reward total was -19.000000. running mean: -19.348786\n","resetting env. episode 532.000000, reward total was -21.000000. running mean: -19.365298\n","resetting env. episode 533.000000, reward total was -16.000000. running mean: -19.331645\n","resetting env. episode 534.000000, reward total was -19.000000. running mean: -19.328329\n","resetting env. episode 535.000000, reward total was -19.000000. running mean: -19.325045\n","resetting env. episode 536.000000, reward total was -18.000000. running mean: -19.311795\n","resetting env. episode 537.000000, reward total was -19.000000. running mean: -19.308677\n","resetting env. episode 538.000000, reward total was -16.000000. running mean: -19.275590\n","resetting env. episode 539.000000, reward total was -19.000000. running mean: -19.272834\n","resetting env. episode 540.000000, reward total was -19.000000. running mean: -19.270106\n","resetting env. episode 541.000000, reward total was -19.000000. running mean: -19.267405\n","resetting env. episode 542.000000, reward total was -18.000000. running mean: -19.254731\n","resetting env. episode 543.000000, reward total was -20.000000. running mean: -19.262183\n","resetting env. episode 544.000000, reward total was -19.000000. running mean: -19.259562\n","resetting env. episode 545.000000, reward total was -20.000000. running mean: -19.266966\n","resetting env. episode 546.000000, reward total was -18.000000. running mean: -19.254296\n","resetting env. episode 547.000000, reward total was -20.000000. running mean: -19.261753\n","resetting env. episode 548.000000, reward total was -20.000000. running mean: -19.269136\n","resetting env. episode 549.000000, reward total was -19.000000. running mean: -19.266444\n","resetting env. episode 550.000000, reward total was -21.000000. running mean: -19.283780\n","resetting env. episode 551.000000, reward total was -19.000000. running mean: -19.280942\n","resetting env. episode 552.000000, reward total was -21.000000. running mean: -19.298133\n","resetting env. episode 553.000000, reward total was -18.000000. running mean: -19.285151\n","resetting env. episode 554.000000, reward total was -17.000000. running mean: -19.262300\n","resetting env. episode 555.000000, reward total was -14.000000. running mean: -19.209677\n","resetting env. episode 556.000000, reward total was -19.000000. running mean: -19.207580\n","resetting env. episode 557.000000, reward total was -21.000000. running mean: -19.225504\n","resetting env. episode 558.000000, reward total was -19.000000. running mean: -19.223249\n","resetting env. episode 559.000000, reward total was -19.000000. running mean: -19.221017\n","resetting env. episode 560.000000, reward total was -21.000000. running mean: -19.238807\n","resetting env. episode 561.000000, reward total was -20.000000. running mean: -19.246419\n","resetting env. episode 562.000000, reward total was -20.000000. running mean: -19.253954\n","resetting env. episode 563.000000, reward total was -20.000000. running mean: -19.261415\n","resetting env. episode 564.000000, reward total was -18.000000. running mean: -19.248801\n","resetting env. episode 565.000000, reward total was -20.000000. running mean: -19.256313\n","resetting env. episode 566.000000, reward total was -17.000000. running mean: -19.233750\n","resetting env. episode 567.000000, reward total was -19.000000. running mean: -19.231412\n","resetting env. episode 568.000000, reward total was -20.000000. running mean: -19.239098\n","resetting env. episode 569.000000, reward total was -17.000000. running mean: -19.216707\n","resetting env. episode 570.000000, reward total was -18.000000. running mean: -19.204540\n","resetting env. episode 571.000000, reward total was -20.000000. running mean: -19.212495\n","resetting env. episode 572.000000, reward total was -19.000000. running mean: -19.210370\n","resetting env. episode 573.000000, reward total was -18.000000. running mean: -19.198266\n","resetting env. episode 574.000000, reward total was -21.000000. running mean: -19.216283\n","resetting env. episode 575.000000, reward total was -19.000000. running mean: -19.214120\n","resetting env. episode 576.000000, reward total was -19.000000. running mean: -19.211979\n","resetting env. episode 577.000000, reward total was -19.000000. running mean: -19.209859\n","resetting env. episode 578.000000, reward total was -19.000000. running mean: -19.207761\n","resetting env. episode 579.000000, reward total was -21.000000. running mean: -19.225683\n","resetting env. episode 580.000000, reward total was -18.000000. running mean: -19.213426\n","resetting env. episode 581.000000, reward total was -19.000000. running mean: -19.211292\n","resetting env. episode 582.000000, reward total was -19.000000. running mean: -19.209179\n","resetting env. episode 583.000000, reward total was -18.000000. running mean: -19.197087\n","resetting env. episode 584.000000, reward total was -16.000000. running mean: -19.165117\n","resetting env. episode 585.000000, reward total was -20.000000. running mean: -19.173465\n","resetting env. episode 586.000000, reward total was -17.000000. running mean: -19.151731\n","resetting env. episode 587.000000, reward total was -20.000000. running mean: -19.160213\n","resetting env. episode 588.000000, reward total was -15.000000. running mean: -19.118611\n","resetting env. episode 589.000000, reward total was -19.000000. running mean: -19.117425\n","resetting env. episode 590.000000, reward total was -18.000000. running mean: -19.106251\n","resetting env. episode 591.000000, reward total was -19.000000. running mean: -19.105188\n","resetting env. episode 592.000000, reward total was -16.000000. running mean: -19.074136\n","resetting env. episode 593.000000, reward total was -20.000000. running mean: -19.083395\n","resetting env. episode 594.000000, reward total was -21.000000. running mean: -19.102561\n","resetting env. episode 595.000000, reward total was -19.000000. running mean: -19.101536\n","resetting env. episode 596.000000, reward total was -15.000000. running mean: -19.060520\n","resetting env. episode 597.000000, reward total was -17.000000. running mean: -19.039915\n","resetting env. episode 598.000000, reward total was -21.000000. running mean: -19.059516\n","resetting env. episode 599.000000, reward total was -19.000000. running mean: -19.058921\n","resetting env. episode 600.000000, reward total was -19.000000. running mean: -19.058331\n","resetting env. episode 601.000000, reward total was -21.000000. running mean: -19.077748\n","resetting env. episode 602.000000, reward total was -18.000000. running mean: -19.066971\n","resetting env. episode 603.000000, reward total was -18.000000. running mean: -19.056301\n","resetting env. episode 604.000000, reward total was -21.000000. running mean: -19.075738\n","resetting env. episode 605.000000, reward total was -15.000000. running mean: -19.034981\n","resetting env. episode 606.000000, reward total was -19.000000. running mean: -19.034631\n","resetting env. episode 607.000000, reward total was -18.000000. running mean: -19.024284\n","resetting env. episode 608.000000, reward total was -18.000000. running mean: -19.014042\n","resetting env. episode 609.000000, reward total was -21.000000. running mean: -19.033901\n","resetting env. episode 610.000000, reward total was -19.000000. running mean: -19.033562\n","resetting env. episode 611.000000, reward total was -18.000000. running mean: -19.023227\n","resetting env. episode 612.000000, reward total was -17.000000. running mean: -19.002994\n","resetting env. episode 613.000000, reward total was -19.000000. running mean: -19.002964\n","resetting env. episode 614.000000, reward total was -20.000000. running mean: -19.012935\n","resetting env. episode 615.000000, reward total was -16.000000. running mean: -18.982805\n","resetting env. episode 616.000000, reward total was -18.000000. running mean: -18.972977\n","resetting env. episode 617.000000, reward total was -19.000000. running mean: -18.973248\n","resetting env. episode 618.000000, reward total was -18.000000. running mean: -18.963515\n","resetting env. episode 619.000000, reward total was -17.000000. running mean: -18.943880\n","resetting env. episode 620.000000, reward total was -20.000000. running mean: -18.954441\n","resetting env. episode 621.000000, reward total was -14.000000. running mean: -18.904897\n","resetting env. episode 622.000000, reward total was -20.000000. running mean: -18.915848\n","resetting env. episode 623.000000, reward total was -17.000000. running mean: -18.896689\n","resetting env. episode 624.000000, reward total was -16.000000. running mean: -18.867722\n","resetting env. episode 625.000000, reward total was -19.000000. running mean: -18.869045\n","resetting env. episode 626.000000, reward total was -14.000000. running mean: -18.820355\n","resetting env. episode 627.000000, reward total was -18.000000. running mean: -18.812151\n","resetting env. episode 628.000000, reward total was -18.000000. running mean: -18.804030\n","resetting env. episode 629.000000, reward total was -14.000000. running mean: -18.755989\n","resetting env. episode 630.000000, reward total was -20.000000. running mean: -18.768429\n","resetting env. episode 631.000000, reward total was -18.000000. running mean: -18.760745\n","resetting env. episode 632.000000, reward total was -17.000000. running mean: -18.743138\n","resetting env. episode 633.000000, reward total was -17.000000. running mean: -18.725706\n","resetting env. episode 634.000000, reward total was -21.000000. running mean: -18.748449\n","resetting env. episode 635.000000, reward total was -17.000000. running mean: -18.730965\n","resetting env. episode 636.000000, reward total was -19.000000. running mean: -18.733655\n","resetting env. episode 637.000000, reward total was -18.000000. running mean: -18.726319\n","resetting env. episode 638.000000, reward total was -20.000000. running mean: -18.739055\n","resetting env. episode 639.000000, reward total was -18.000000. running mean: -18.731665\n","resetting env. episode 640.000000, reward total was -18.000000. running mean: -18.724348\n","resetting env. episode 641.000000, reward total was -19.000000. running mean: -18.727105\n","resetting env. episode 642.000000, reward total was -20.000000. running mean: -18.739834\n","resetting env. episode 643.000000, reward total was -19.000000. running mean: -18.742435\n","resetting env. episode 644.000000, reward total was -21.000000. running mean: -18.765011\n","resetting env. episode 645.000000, reward total was -15.000000. running mean: -18.727361\n","resetting env. episode 646.000000, reward total was -13.000000. running mean: -18.670087\n","resetting env. episode 647.000000, reward total was -19.000000. running mean: -18.673386\n","resetting env. episode 648.000000, reward total was -18.000000. running mean: -18.666653\n","resetting env. episode 649.000000, reward total was -20.000000. running mean: -18.679986\n","resetting env. episode 650.000000, reward total was -19.000000. running mean: -18.683186\n","resetting env. episode 651.000000, reward total was -17.000000. running mean: -18.666354\n","resetting env. episode 652.000000, reward total was -18.000000. running mean: -18.659691\n","resetting env. episode 653.000000, reward total was -19.000000. running mean: -18.663094\n","resetting env. episode 654.000000, reward total was -21.000000. running mean: -18.686463\n","resetting env. episode 655.000000, reward total was -18.000000. running mean: -18.679598\n","resetting env. episode 656.000000, reward total was -19.000000. running mean: -18.682802\n","resetting env. episode 657.000000, reward total was -15.000000. running mean: -18.645974\n","resetting env. episode 658.000000, reward total was -17.000000. running mean: -18.629515\n","resetting env. episode 659.000000, reward total was -17.000000. running mean: -18.613219\n","resetting env. episode 660.000000, reward total was -19.000000. running mean: -18.617087\n","resetting env. episode 661.000000, reward total was -17.000000. running mean: -18.600916\n","resetting env. episode 662.000000, reward total was -19.000000. running mean: -18.604907\n","resetting env. episode 663.000000, reward total was -19.000000. running mean: -18.608858\n","resetting env. episode 664.000000, reward total was -19.000000. running mean: -18.612769\n","resetting env. episode 665.000000, reward total was -21.000000. running mean: -18.636642\n","resetting env. episode 666.000000, reward total was -16.000000. running mean: -18.610275\n","resetting env. episode 667.000000, reward total was -19.000000. running mean: -18.614173\n","resetting env. episode 668.000000, reward total was -17.000000. running mean: -18.598031\n","resetting env. episode 669.000000, reward total was -18.000000. running mean: -18.592051\n","resetting env. episode 670.000000, reward total was -13.000000. running mean: -18.536130\n","resetting env. episode 671.000000, reward total was -16.000000. running mean: -18.510769\n","resetting env. episode 672.000000, reward total was -20.000000. running mean: -18.525661\n","resetting env. episode 673.000000, reward total was -14.000000. running mean: -18.480404\n","resetting env. episode 674.000000, reward total was -17.000000. running mean: -18.465600\n","resetting env. episode 675.000000, reward total was -18.000000. running mean: -18.460944\n","resetting env. episode 676.000000, reward total was -11.000000. running mean: -18.386335\n","resetting env. episode 677.000000, reward total was -14.000000. running mean: -18.342472\n","resetting env. episode 678.000000, reward total was -19.000000. running mean: -18.349047\n","resetting env. episode 679.000000, reward total was -16.000000. running mean: -18.325556\n","resetting env. episode 680.000000, reward total was -18.000000. running mean: -18.322301\n","resetting env. episode 681.000000, reward total was -17.000000. running mean: -18.309078\n","resetting env. episode 682.000000, reward total was -18.000000. running mean: -18.305987\n","resetting env. episode 683.000000, reward total was -18.000000. running mean: -18.302927\n","resetting env. episode 684.000000, reward total was -17.000000. running mean: -18.289898\n","resetting env. episode 685.000000, reward total was -18.000000. running mean: -18.286999\n","resetting env. episode 686.000000, reward total was -18.000000. running mean: -18.284129\n","resetting env. episode 687.000000, reward total was -15.000000. running mean: -18.251288\n","resetting env. episode 688.000000, reward total was -15.000000. running mean: -18.218775\n","resetting env. episode 689.000000, reward total was -16.000000. running mean: -18.196587\n","resetting env. episode 690.000000, reward total was -18.000000. running mean: -18.194621\n","resetting env. episode 691.000000, reward total was -19.000000. running mean: -18.202675\n","resetting env. episode 692.000000, reward total was -17.000000. running mean: -18.190648\n","resetting env. episode 693.000000, reward total was -20.000000. running mean: -18.208742\n","resetting env. episode 694.000000, reward total was -18.000000. running mean: -18.206654\n","resetting env. episode 695.000000, reward total was -19.000000. running mean: -18.214588\n","resetting env. episode 696.000000, reward total was -18.000000. running mean: -18.212442\n","resetting env. episode 697.000000, reward total was -15.000000. running mean: -18.180317\n","resetting env. episode 698.000000, reward total was -19.000000. running mean: -18.188514\n","resetting env. episode 699.000000, reward total was -18.000000. running mean: -18.186629\n","resetting env. episode 700.000000, reward total was -19.000000. running mean: -18.194763\n","resetting env. episode 701.000000, reward total was -18.000000. running mean: -18.192815\n","resetting env. episode 702.000000, reward total was -20.000000. running mean: -18.210887\n","resetting env. episode 703.000000, reward total was -16.000000. running mean: -18.188778\n","resetting env. episode 704.000000, reward total was -15.000000. running mean: -18.156890\n","resetting env. episode 705.000000, reward total was -13.000000. running mean: -18.105322\n","resetting env. episode 706.000000, reward total was -18.000000. running mean: -18.104268\n","resetting env. episode 707.000000, reward total was -17.000000. running mean: -18.093226\n","resetting env. episode 708.000000, reward total was -18.000000. running mean: -18.092293\n","resetting env. episode 709.000000, reward total was -20.000000. running mean: -18.111370\n","resetting env. episode 710.000000, reward total was -19.000000. running mean: -18.120257\n","resetting env. episode 711.000000, reward total was -19.000000. running mean: -18.129054\n","resetting env. episode 712.000000, reward total was -15.000000. running mean: -18.097764\n","resetting env. episode 713.000000, reward total was -17.000000. running mean: -18.086786\n","resetting env. episode 714.000000, reward total was -16.000000. running mean: -18.065918\n","resetting env. episode 715.000000, reward total was -17.000000. running mean: -18.055259\n","resetting env. episode 716.000000, reward total was -17.000000. running mean: -18.044706\n","resetting env. episode 717.000000, reward total was -18.000000. running mean: -18.044259\n","resetting env. episode 718.000000, reward total was -18.000000. running mean: -18.043817\n","resetting env. episode 719.000000, reward total was -17.000000. running mean: -18.033379\n","resetting env. episode 720.000000, reward total was -17.000000. running mean: -18.023045\n","resetting env. episode 721.000000, reward total was -19.000000. running mean: -18.032814\n","resetting env. episode 722.000000, reward total was -20.000000. running mean: -18.052486\n","resetting env. episode 723.000000, reward total was -19.000000. running mean: -18.061961\n","resetting env. episode 724.000000, reward total was -15.000000. running mean: -18.031342\n","resetting env. episode 725.000000, reward total was -17.000000. running mean: -18.021028\n","resetting env. episode 726.000000, reward total was -15.000000. running mean: -17.990818\n","resetting env. episode 727.000000, reward total was -15.000000. running mean: -17.960910\n","resetting env. episode 728.000000, reward total was -17.000000. running mean: -17.951301\n","resetting env. episode 729.000000, reward total was -17.000000. running mean: -17.941788\n","resetting env. episode 730.000000, reward total was -11.000000. running mean: -17.872370\n","resetting env. episode 731.000000, reward total was -21.000000. running mean: -17.903646\n","resetting env. episode 732.000000, reward total was -16.000000. running mean: -17.884610\n","resetting env. episode 733.000000, reward total was -18.000000. running mean: -17.885764\n","resetting env. episode 734.000000, reward total was -19.000000. running mean: -17.896906\n","resetting env. episode 735.000000, reward total was -17.000000. running mean: -17.887937\n","resetting env. episode 736.000000, reward total was -14.000000. running mean: -17.849058\n","resetting env. episode 737.000000, reward total was -15.000000. running mean: -17.820567\n","resetting env. episode 738.000000, reward total was -15.000000. running mean: -17.792361\n","resetting env. episode 739.000000, reward total was -17.000000. running mean: -17.784438\n","resetting env. episode 740.000000, reward total was -18.000000. running mean: -17.786593\n","resetting env. episode 741.000000, reward total was -19.000000. running mean: -17.798727\n","resetting env. episode 742.000000, reward total was -18.000000. running mean: -17.800740\n","resetting env. episode 743.000000, reward total was -19.000000. running mean: -17.812733\n","resetting env. episode 744.000000, reward total was -20.000000. running mean: -17.834605\n","resetting env. episode 745.000000, reward total was -19.000000. running mean: -17.846259\n","resetting env. episode 746.000000, reward total was -18.000000. running mean: -17.847797\n","resetting env. episode 747.000000, reward total was -18.000000. running mean: -17.849319\n","resetting env. episode 748.000000, reward total was -16.000000. running mean: -17.830826\n","resetting env. episode 749.000000, reward total was -15.000000. running mean: -17.802517\n","resetting env. episode 750.000000, reward total was -21.000000. running mean: -17.834492\n","resetting env. episode 751.000000, reward total was -17.000000. running mean: -17.826147\n","resetting env. episode 752.000000, reward total was -19.000000. running mean: -17.837886\n","resetting env. episode 753.000000, reward total was -18.000000. running mean: -17.839507\n","resetting env. episode 754.000000, reward total was -21.000000. running mean: -17.871112\n","resetting env. episode 755.000000, reward total was -14.000000. running mean: -17.832401\n","resetting env. episode 756.000000, reward total was -20.000000. running mean: -17.854077\n","resetting env. episode 757.000000, reward total was -16.000000. running mean: -17.835536\n","resetting env. episode 758.000000, reward total was -15.000000. running mean: -17.807181\n","resetting env. episode 759.000000, reward total was -17.000000. running mean: -17.799109\n","resetting env. episode 760.000000, reward total was -19.000000. running mean: -17.811118\n","resetting env. episode 761.000000, reward total was -19.000000. running mean: -17.823006\n","resetting env. episode 762.000000, reward total was -17.000000. running mean: -17.814776\n","resetting env. episode 763.000000, reward total was -15.000000. running mean: -17.786629\n","resetting env. episode 764.000000, reward total was -18.000000. running mean: -17.788762\n","resetting env. episode 765.000000, reward total was -16.000000. running mean: -17.770875\n","resetting env. episode 766.000000, reward total was -18.000000. running mean: -17.773166\n","resetting env. episode 767.000000, reward total was -18.000000. running mean: -17.775434\n","resetting env. episode 768.000000, reward total was -19.000000. running mean: -17.787680\n","resetting env. episode 769.000000, reward total was -18.000000. running mean: -17.789803\n","resetting env. episode 770.000000, reward total was -16.000000. running mean: -17.771905\n","resetting env. episode 771.000000, reward total was -15.000000. running mean: -17.744186\n","resetting env. episode 772.000000, reward total was -18.000000. running mean: -17.746744\n","resetting env. episode 773.000000, reward total was -16.000000. running mean: -17.729277\n","resetting env. episode 774.000000, reward total was -21.000000. running mean: -17.761984\n","resetting env. episode 775.000000, reward total was -18.000000. running mean: -17.764364\n","resetting env. episode 776.000000, reward total was -19.000000. running mean: -17.776721\n","resetting env. episode 777.000000, reward total was -15.000000. running mean: -17.748953\n","resetting env. episode 778.000000, reward total was -18.000000. running mean: -17.751464\n","resetting env. episode 779.000000, reward total was -18.000000. running mean: -17.753949\n","resetting env. episode 780.000000, reward total was -17.000000. running mean: -17.746410\n","resetting env. episode 781.000000, reward total was -19.000000. running mean: -17.758946\n","resetting env. episode 782.000000, reward total was -14.000000. running mean: -17.721356\n","resetting env. episode 783.000000, reward total was -18.000000. running mean: -17.724143\n","resetting env. episode 784.000000, reward total was -17.000000. running mean: -17.716901\n","resetting env. episode 785.000000, reward total was -17.000000. running mean: -17.709732\n","resetting env. episode 786.000000, reward total was -18.000000. running mean: -17.712635\n","resetting env. episode 787.000000, reward total was -15.000000. running mean: -17.685508\n","resetting env. episode 788.000000, reward total was -19.000000. running mean: -17.698653\n","resetting env. episode 789.000000, reward total was -16.000000. running mean: -17.681667\n","resetting env. episode 790.000000, reward total was -14.000000. running mean: -17.644850\n","resetting env. episode 791.000000, reward total was -19.000000. running mean: -17.658402\n","resetting env. episode 792.000000, reward total was -19.000000. running mean: -17.671818\n","resetting env. episode 793.000000, reward total was -20.000000. running mean: -17.695099\n","resetting env. episode 794.000000, reward total was -21.000000. running mean: -17.728148\n","resetting env. episode 795.000000, reward total was -15.000000. running mean: -17.700867\n","resetting env. episode 796.000000, reward total was -16.000000. running mean: -17.683858\n","resetting env. episode 797.000000, reward total was -18.000000. running mean: -17.687020\n","resetting env. episode 798.000000, reward total was -17.000000. running mean: -17.680150\n","resetting env. episode 799.000000, reward total was -17.000000. running mean: -17.673348\n","resetting env. episode 800.000000, reward total was -17.000000. running mean: -17.666615\n","resetting env. episode 801.000000, reward total was -20.000000. running mean: -17.689948\n","resetting env. episode 802.000000, reward total was -21.000000. running mean: -17.723049\n","resetting env. episode 803.000000, reward total was -15.000000. running mean: -17.695818\n","resetting env. episode 804.000000, reward total was -16.000000. running mean: -17.678860\n","resetting env. episode 805.000000, reward total was -19.000000. running mean: -17.692072\n","resetting env. episode 806.000000, reward total was -14.000000. running mean: -17.655151\n","resetting env. episode 807.000000, reward total was -14.000000. running mean: -17.618599\n","resetting env. episode 808.000000, reward total was -17.000000. running mean: -17.612413\n","resetting env. episode 809.000000, reward total was -16.000000. running mean: -17.596289\n","resetting env. episode 810.000000, reward total was -16.000000. running mean: -17.580326\n","resetting env. episode 811.000000, reward total was -17.000000. running mean: -17.574523\n","resetting env. episode 812.000000, reward total was -17.000000. running mean: -17.568778\n","resetting env. episode 813.000000, reward total was -17.000000. running mean: -17.563090\n","resetting env. episode 814.000000, reward total was -18.000000. running mean: -17.567459\n","resetting env. episode 815.000000, reward total was -17.000000. running mean: -17.561785\n","resetting env. episode 816.000000, reward total was -19.000000. running mean: -17.576167\n","resetting env. episode 817.000000, reward total was -18.000000. running mean: -17.580405\n","resetting env. episode 818.000000, reward total was -14.000000. running mean: -17.544601\n","resetting env. episode 819.000000, reward total was -17.000000. running mean: -17.539155\n","resetting env. episode 820.000000, reward total was -18.000000. running mean: -17.543764\n","resetting env. episode 821.000000, reward total was -16.000000. running mean: -17.528326\n","resetting env. episode 822.000000, reward total was -17.000000. running mean: -17.523043\n","resetting env. episode 823.000000, reward total was -17.000000. running mean: -17.517812\n","resetting env. episode 824.000000, reward total was -19.000000. running mean: -17.532634\n","resetting env. episode 825.000000, reward total was -15.000000. running mean: -17.507308\n","resetting env. episode 826.000000, reward total was -17.000000. running mean: -17.502235\n","resetting env. episode 827.000000, reward total was -16.000000. running mean: -17.487212\n","resetting env. episode 828.000000, reward total was -20.000000. running mean: -17.512340\n","resetting env. episode 829.000000, reward total was -16.000000. running mean: -17.497217\n","resetting env. episode 830.000000, reward total was -18.000000. running mean: -17.502245\n","resetting env. episode 831.000000, reward total was -18.000000. running mean: -17.507222\n","resetting env. episode 832.000000, reward total was -16.000000. running mean: -17.492150\n","resetting env. episode 833.000000, reward total was -19.000000. running mean: -17.507228\n","resetting env. episode 834.000000, reward total was -20.000000. running mean: -17.532156\n","resetting env. episode 835.000000, reward total was -20.000000. running mean: -17.556835\n","resetting env. episode 836.000000, reward total was -15.000000. running mean: -17.531266\n","resetting env. episode 837.000000, reward total was -11.000000. running mean: -17.465954\n","resetting env. episode 838.000000, reward total was -12.000000. running mean: -17.411294\n","resetting env. episode 839.000000, reward total was -17.000000. running mean: -17.407181\n","resetting env. episode 840.000000, reward total was -16.000000. running mean: -17.393109\n","resetting env. episode 841.000000, reward total was -16.000000. running mean: -17.379178\n","resetting env. episode 842.000000, reward total was -14.000000. running mean: -17.345386\n","resetting env. episode 843.000000, reward total was -19.000000. running mean: -17.361933\n","resetting env. episode 844.000000, reward total was -17.000000. running mean: -17.358313\n","resetting env. episode 845.000000, reward total was -15.000000. running mean: -17.334730\n","resetting env. episode 846.000000, reward total was -14.000000. running mean: -17.301383\n","resetting env. episode 847.000000, reward total was -17.000000. running mean: -17.298369\n","resetting env. episode 848.000000, reward total was -19.000000. running mean: -17.315385\n","resetting env. episode 849.000000, reward total was -17.000000. running mean: -17.312231\n","resetting env. episode 850.000000, reward total was -16.000000. running mean: -17.299109\n","resetting env. episode 851.000000, reward total was -15.000000. running mean: -17.276118\n","resetting env. episode 852.000000, reward total was -20.000000. running mean: -17.303357\n","resetting env. episode 853.000000, reward total was -14.000000. running mean: -17.270323\n","resetting env. episode 854.000000, reward total was -14.000000. running mean: -17.237620\n","resetting env. episode 855.000000, reward total was -17.000000. running mean: -17.235244\n","resetting env. episode 856.000000, reward total was -16.000000. running mean: -17.222891\n","resetting env. episode 857.000000, reward total was -17.000000. running mean: -17.220663\n","resetting env. episode 858.000000, reward total was -13.000000. running mean: -17.178456\n","resetting env. episode 859.000000, reward total was -18.000000. running mean: -17.186671\n","resetting env. episode 860.000000, reward total was -11.000000. running mean: -17.124805\n","resetting env. episode 861.000000, reward total was -15.000000. running mean: -17.103557\n","resetting env. episode 862.000000, reward total was -20.000000. running mean: -17.132521\n","resetting env. episode 863.000000, reward total was -17.000000. running mean: -17.131196\n","resetting env. episode 864.000000, reward total was -14.000000. running mean: -17.099884\n","resetting env. episode 865.000000, reward total was -15.000000. running mean: -17.078885\n","resetting env. episode 866.000000, reward total was -9.000000. running mean: -16.998096\n","resetting env. episode 867.000000, reward total was -19.000000. running mean: -17.018115\n","resetting env. episode 868.000000, reward total was -17.000000. running mean: -17.017934\n","resetting env. episode 869.000000, reward total was -18.000000. running mean: -17.027755\n","resetting env. episode 870.000000, reward total was -19.000000. running mean: -17.047477\n","resetting env. episode 871.000000, reward total was -18.000000. running mean: -17.057002\n","resetting env. episode 872.000000, reward total was -17.000000. running mean: -17.056432\n","resetting env. episode 873.000000, reward total was -9.000000. running mean: -16.975868\n","resetting env. episode 874.000000, reward total was -17.000000. running mean: -16.976109\n","resetting env. episode 875.000000, reward total was -15.000000. running mean: -16.956348\n","resetting env. episode 876.000000, reward total was -19.000000. running mean: -16.976785\n","resetting env. episode 877.000000, reward total was -16.000000. running mean: -16.967017\n","resetting env. episode 878.000000, reward total was -19.000000. running mean: -16.987347\n","resetting env. episode 879.000000, reward total was -17.000000. running mean: -16.987473\n","resetting env. episode 880.000000, reward total was -17.000000. running mean: -16.987599\n","resetting env. episode 881.000000, reward total was -18.000000. running mean: -16.997723\n","resetting env. episode 882.000000, reward total was -17.000000. running mean: -16.997745\n","resetting env. episode 883.000000, reward total was -17.000000. running mean: -16.997768\n","resetting env. episode 884.000000, reward total was -15.000000. running mean: -16.977790\n","resetting env. episode 885.000000, reward total was -17.000000. running mean: -16.978012\n","resetting env. episode 886.000000, reward total was -19.000000. running mean: -16.998232\n","resetting env. episode 887.000000, reward total was -15.000000. running mean: -16.978250\n","resetting env. episode 888.000000, reward total was -16.000000. running mean: -16.968467\n","resetting env. episode 889.000000, reward total was -18.000000. running mean: -16.978783\n","resetting env. episode 890.000000, reward total was -16.000000. running mean: -16.968995\n","resetting env. episode 891.000000, reward total was -18.000000. running mean: -16.979305\n","resetting env. episode 892.000000, reward total was -17.000000. running mean: -16.979512\n","resetting env. episode 893.000000, reward total was -15.000000. running mean: -16.959717\n","resetting env. episode 894.000000, reward total was -17.000000. running mean: -16.960120\n","resetting env. episode 895.000000, reward total was -18.000000. running mean: -16.970518\n","resetting env. episode 896.000000, reward total was -16.000000. running mean: -16.960813\n","resetting env. episode 897.000000, reward total was -16.000000. running mean: -16.951205\n","resetting env. episode 898.000000, reward total was -20.000000. running mean: -16.981693\n","resetting env. episode 899.000000, reward total was -16.000000. running mean: -16.971876\n","resetting env. episode 900.000000, reward total was -18.000000. running mean: -16.982157\n","resetting env. episode 901.000000, reward total was -15.000000. running mean: -16.962336\n","resetting env. episode 902.000000, reward total was -13.000000. running mean: -16.922712\n","resetting env. episode 903.000000, reward total was -16.000000. running mean: -16.913485\n","resetting env. episode 904.000000, reward total was -15.000000. running mean: -16.894350\n","resetting env. episode 905.000000, reward total was -18.000000. running mean: -16.905407\n","resetting env. episode 906.000000, reward total was -13.000000. running mean: -16.866353\n","resetting env. episode 907.000000, reward total was -19.000000. running mean: -16.887689\n","resetting env. episode 908.000000, reward total was -17.000000. running mean: -16.888812\n","resetting env. episode 909.000000, reward total was -16.000000. running mean: -16.879924\n","resetting env. episode 910.000000, reward total was -16.000000. running mean: -16.871125\n","resetting env. episode 911.000000, reward total was -15.000000. running mean: -16.852414\n","resetting env. episode 912.000000, reward total was -17.000000. running mean: -16.853890\n","resetting env. episode 913.000000, reward total was -18.000000. running mean: -16.865351\n","resetting env. episode 914.000000, reward total was -15.000000. running mean: -16.846697\n","resetting env. episode 915.000000, reward total was -19.000000. running mean: -16.868230\n","resetting env. episode 916.000000, reward total was -12.000000. running mean: -16.819548\n","resetting env. episode 917.000000, reward total was -18.000000. running mean: -16.831353\n","resetting env. episode 918.000000, reward total was -14.000000. running mean: -16.803039\n","resetting env. episode 919.000000, reward total was -14.000000. running mean: -16.775009\n","resetting env. episode 920.000000, reward total was -11.000000. running mean: -16.717259\n","resetting env. episode 921.000000, reward total was -18.000000. running mean: -16.730086\n","resetting env. episode 922.000000, reward total was -15.000000. running mean: -16.712785\n","resetting env. episode 923.000000, reward total was -17.000000. running mean: -16.715657\n","resetting env. episode 924.000000, reward total was -16.000000. running mean: -16.708501\n","resetting env. episode 925.000000, reward total was -15.000000. running mean: -16.691416\n","resetting env. episode 926.000000, reward total was -17.000000. running mean: -16.694501\n","resetting env. episode 927.000000, reward total was -13.000000. running mean: -16.657556\n","resetting env. episode 928.000000, reward total was -15.000000. running mean: -16.640981\n","resetting env. episode 929.000000, reward total was -16.000000. running mean: -16.634571\n","resetting env. episode 930.000000, reward total was -19.000000. running mean: -16.658225\n","resetting env. episode 931.000000, reward total was -9.000000. running mean: -16.581643\n","resetting env. episode 932.000000, reward total was -16.000000. running mean: -16.575827\n","resetting env. episode 933.000000, reward total was -19.000000. running mean: -16.600068\n","resetting env. episode 934.000000, reward total was -17.000000. running mean: -16.604068\n","resetting env. episode 935.000000, reward total was -18.000000. running mean: -16.618027\n","resetting env. episode 936.000000, reward total was -13.000000. running mean: -16.581847\n","resetting env. episode 937.000000, reward total was -13.000000. running mean: -16.546028\n","resetting env. episode 938.000000, reward total was -19.000000. running mean: -16.570568\n","resetting env. episode 939.000000, reward total was -15.000000. running mean: -16.554862\n","resetting env. episode 940.000000, reward total was -17.000000. running mean: -16.559314\n","resetting env. episode 941.000000, reward total was -17.000000. running mean: -16.563721\n","resetting env. episode 942.000000, reward total was -21.000000. running mean: -16.608083\n","resetting env. episode 943.000000, reward total was -19.000000. running mean: -16.632003\n","resetting env. episode 944.000000, reward total was -14.000000. running mean: -16.605683\n","resetting env. episode 945.000000, reward total was -15.000000. running mean: -16.589626\n","resetting env. episode 946.000000, reward total was -17.000000. running mean: -16.593729\n","resetting env. episode 947.000000, reward total was -16.000000. running mean: -16.587792\n","resetting env. episode 948.000000, reward total was -14.000000. running mean: -16.561914\n","resetting env. episode 949.000000, reward total was -15.000000. running mean: -16.546295\n","resetting env. episode 950.000000, reward total was -18.000000. running mean: -16.560832\n","resetting env. episode 951.000000, reward total was -17.000000. running mean: -16.565224\n","resetting env. episode 952.000000, reward total was -16.000000. running mean: -16.559572\n","resetting env. episode 953.000000, reward total was -13.000000. running mean: -16.523976\n","resetting env. episode 954.000000, reward total was -15.000000. running mean: -16.508736\n","resetting env. episode 955.000000, reward total was -15.000000. running mean: -16.493649\n","resetting env. episode 956.000000, reward total was -17.000000. running mean: -16.498712\n","resetting env. episode 957.000000, reward total was -21.000000. running mean: -16.543725\n","resetting env. episode 958.000000, reward total was -15.000000. running mean: -16.528288\n","resetting env. episode 959.000000, reward total was -21.000000. running mean: -16.573005\n","resetting env. episode 960.000000, reward total was -12.000000. running mean: -16.527275\n","resetting env. episode 961.000000, reward total was -15.000000. running mean: -16.512002\n","resetting env. episode 962.000000, reward total was -16.000000. running mean: -16.506882\n","resetting env. episode 963.000000, reward total was -19.000000. running mean: -16.531813\n","resetting env. episode 964.000000, reward total was -17.000000. running mean: -16.536495\n","resetting env. episode 965.000000, reward total was -20.000000. running mean: -16.571130\n","resetting env. episode 966.000000, reward total was -13.000000. running mean: -16.535419\n","resetting env. episode 967.000000, reward total was -13.000000. running mean: -16.500065\n","resetting env. episode 968.000000, reward total was -17.000000. running mean: -16.505064\n","resetting env. episode 969.000000, reward total was -13.000000. running mean: -16.470013\n","resetting env. episode 970.000000, reward total was -15.000000. running mean: -16.455313\n","resetting env. episode 971.000000, reward total was -17.000000. running mean: -16.460760\n","resetting env. episode 972.000000, reward total was -15.000000. running mean: -16.446153\n","resetting env. episode 973.000000, reward total was -11.000000. running mean: -16.391691\n","resetting env. episode 974.000000, reward total was -16.000000. running mean: -16.387774\n","resetting env. episode 975.000000, reward total was -19.000000. running mean: -16.413896\n","resetting env. episode 976.000000, reward total was -18.000000. running mean: -16.429757\n","resetting env. episode 977.000000, reward total was -16.000000. running mean: -16.425460\n","resetting env. episode 978.000000, reward total was -15.000000. running mean: -16.411205\n","resetting env. episode 979.000000, reward total was -15.000000. running mean: -16.397093\n","resetting env. episode 980.000000, reward total was -14.000000. running mean: -16.373122\n","resetting env. episode 981.000000, reward total was -15.000000. running mean: -16.359391\n","resetting env. episode 982.000000, reward total was -13.000000. running mean: -16.325797\n","resetting env. episode 983.000000, reward total was -10.000000. running mean: -16.262539\n","resetting env. episode 984.000000, reward total was -17.000000. running mean: -16.269914\n","resetting env. episode 985.000000, reward total was -15.000000. running mean: -16.257215\n","resetting env. episode 986.000000, reward total was -16.000000. running mean: -16.254643\n","resetting env. episode 987.000000, reward total was -14.000000. running mean: -16.232096\n","resetting env. episode 988.000000, reward total was -15.000000. running mean: -16.219775\n","resetting env. episode 989.000000, reward total was -16.000000. running mean: -16.217577\n","resetting env. episode 990.000000, reward total was -21.000000. running mean: -16.265402\n","resetting env. episode 991.000000, reward total was -11.000000. running mean: -16.212748\n","resetting env. episode 992.000000, reward total was -17.000000. running mean: -16.220620\n","resetting env. episode 993.000000, reward total was -16.000000. running mean: -16.218414\n","resetting env. episode 994.000000, reward total was -17.000000. running mean: -16.226230\n","resetting env. episode 995.000000, reward total was -11.000000. running mean: -16.173967\n","resetting env. episode 996.000000, reward total was -19.000000. running mean: -16.202228\n","resetting env. episode 997.000000, reward total was -18.000000. running mean: -16.220206\n","resetting env. episode 998.000000, reward total was -6.000000. running mean: -16.118003\n","resetting env. episode 999.000000, reward total was -15.000000. running mean: -16.106823\n","resetting env. episode 1000.000000, reward total was -18.000000. running mean: -16.125755\n","resetting env. episode 1001.000000, reward total was -12.000000. running mean: -16.084498\n","resetting env. episode 1002.000000, reward total was -10.000000. running mean: -16.023653\n","resetting env. episode 1003.000000, reward total was -16.000000. running mean: -16.023416\n","resetting env. episode 1004.000000, reward total was -15.000000. running mean: -16.013182\n","resetting env. episode 1005.000000, reward total was -18.000000. running mean: -16.033050\n","resetting env. episode 1006.000000, reward total was -20.000000. running mean: -16.072720\n","resetting env. episode 1007.000000, reward total was -14.000000. running mean: -16.051992\n","resetting env. episode 1008.000000, reward total was -15.000000. running mean: -16.041473\n","resetting env. episode 1009.000000, reward total was -15.000000. running mean: -16.031058\n","resetting env. episode 1010.000000, reward total was -13.000000. running mean: -16.000747\n","resetting env. episode 1011.000000, reward total was -19.000000. running mean: -16.030740\n","resetting env. episode 1012.000000, reward total was -18.000000. running mean: -16.050432\n","resetting env. episode 1013.000000, reward total was -19.000000. running mean: -16.079928\n","resetting env. episode 1014.000000, reward total was -17.000000. running mean: -16.089129\n","resetting env. episode 1015.000000, reward total was -12.000000. running mean: -16.048237\n","resetting env. episode 1016.000000, reward total was -9.000000. running mean: -15.977755\n","resetting env. episode 1017.000000, reward total was -17.000000. running mean: -15.987978\n","resetting env. episode 1018.000000, reward total was -16.000000. running mean: -15.988098\n","resetting env. episode 1019.000000, reward total was -19.000000. running mean: -16.018217\n","resetting env. episode 1020.000000, reward total was -15.000000. running mean: -16.008035\n","resetting env. episode 1021.000000, reward total was -11.000000. running mean: -15.957954\n","resetting env. episode 1022.000000, reward total was -15.000000. running mean: -15.948375\n","resetting env. episode 1023.000000, reward total was -16.000000. running mean: -15.948891\n","resetting env. episode 1024.000000, reward total was -20.000000. running mean: -15.989402\n","resetting env. episode 1025.000000, reward total was -14.000000. running mean: -15.969508\n","resetting env. episode 1026.000000, reward total was -18.000000. running mean: -15.989813\n","resetting env. episode 1027.000000, reward total was -20.000000. running mean: -16.029915\n","resetting env. episode 1028.000000, reward total was -14.000000. running mean: -16.009616\n","resetting env. episode 1029.000000, reward total was -15.000000. running mean: -15.999520\n","resetting env. episode 1030.000000, reward total was -14.000000. running mean: -15.979524\n","resetting env. episode 1031.000000, reward total was -13.000000. running mean: -15.949729\n","resetting env. episode 1032.000000, reward total was -16.000000. running mean: -15.950232\n","resetting env. episode 1033.000000, reward total was -17.000000. running mean: -15.960730\n","resetting env. episode 1034.000000, reward total was -20.000000. running mean: -16.001122\n","resetting env. episode 1035.000000, reward total was -15.000000. running mean: -15.991111\n","resetting env. episode 1036.000000, reward total was -12.000000. running mean: -15.951200\n","resetting env. episode 1037.000000, reward total was -19.000000. running mean: -15.981688\n","resetting env. episode 1038.000000, reward total was -15.000000. running mean: -15.971871\n","resetting env. episode 1039.000000, reward total was -18.000000. running mean: -15.992152\n","resetting env. episode 1040.000000, reward total was -17.000000. running mean: -16.002231\n","resetting env. episode 1041.000000, reward total was -17.000000. running mean: -16.012208\n","resetting env. episode 1042.000000, reward total was -10.000000. running mean: -15.952086\n","resetting env. episode 1043.000000, reward total was -12.000000. running mean: -15.912566\n","resetting env. episode 1044.000000, reward total was -13.000000. running mean: -15.883440\n","resetting env. episode 1045.000000, reward total was -13.000000. running mean: -15.854605\n","resetting env. episode 1046.000000, reward total was -18.000000. running mean: -15.876059\n","resetting env. episode 1047.000000, reward total was -14.000000. running mean: -15.857299\n","resetting env. episode 1048.000000, reward total was -18.000000. running mean: -15.878726\n","resetting env. episode 1049.000000, reward total was -13.000000. running mean: -15.849939\n","resetting env. episode 1050.000000, reward total was -12.000000. running mean: -15.811439\n","resetting env. episode 1051.000000, reward total was -17.000000. running mean: -15.823325\n","resetting env. episode 1052.000000, reward total was -17.000000. running mean: -15.835092\n","resetting env. episode 1053.000000, reward total was -13.000000. running mean: -15.806741\n","resetting env. episode 1054.000000, reward total was -15.000000. running mean: -15.798673\n","resetting env. episode 1055.000000, reward total was -17.000000. running mean: -15.810686\n","resetting env. episode 1056.000000, reward total was -17.000000. running mean: -15.822580\n","resetting env. episode 1057.000000, reward total was -12.000000. running mean: -15.784354\n","resetting env. episode 1058.000000, reward total was -12.000000. running mean: -15.746510\n","resetting env. episode 1059.000000, reward total was -19.000000. running mean: -15.779045\n","resetting env. episode 1060.000000, reward total was -17.000000. running mean: -15.791255\n","resetting env. episode 1061.000000, reward total was -10.000000. running mean: -15.733342\n","resetting env. episode 1062.000000, reward total was -15.000000. running mean: -15.726009\n","resetting env. episode 1063.000000, reward total was -16.000000. running mean: -15.728749\n","resetting env. episode 1064.000000, reward total was -18.000000. running mean: -15.751461\n","resetting env. episode 1065.000000, reward total was -15.000000. running mean: -15.743947\n","resetting env. episode 1066.000000, reward total was -13.000000. running mean: -15.716507\n","resetting env. episode 1067.000000, reward total was -12.000000. running mean: -15.679342\n","resetting env. episode 1068.000000, reward total was -15.000000. running mean: -15.672549\n","resetting env. episode 1069.000000, reward total was -19.000000. running mean: -15.705823\n","resetting env. episode 1070.000000, reward total was -19.000000. running mean: -15.738765\n","resetting env. episode 1071.000000, reward total was -13.000000. running mean: -15.711377\n","resetting env. episode 1072.000000, reward total was -14.000000. running mean: -15.694263\n","resetting env. episode 1073.000000, reward total was -17.000000. running mean: -15.707321\n","resetting env. episode 1074.000000, reward total was -17.000000. running mean: -15.720248\n","resetting env. episode 1075.000000, reward total was -17.000000. running mean: -15.733045\n","resetting env. episode 1076.000000, reward total was -12.000000. running mean: -15.695715\n","resetting env. episode 1077.000000, reward total was -17.000000. running mean: -15.708758\n","resetting env. episode 1078.000000, reward total was -15.000000. running mean: -15.701670\n","resetting env. episode 1079.000000, reward total was -19.000000. running mean: -15.734653\n","resetting env. episode 1080.000000, reward total was -16.000000. running mean: -15.737307\n","resetting env. episode 1081.000000, reward total was -14.000000. running mean: -15.719934\n","resetting env. episode 1082.000000, reward total was -9.000000. running mean: -15.652734\n","resetting env. episode 1083.000000, reward total was -18.000000. running mean: -15.676207\n","resetting env. episode 1084.000000, reward total was -16.000000. running mean: -15.679445\n","resetting env. episode 1085.000000, reward total was -11.000000. running mean: -15.632650\n","resetting env. episode 1086.000000, reward total was -15.000000. running mean: -15.626324\n","resetting env. episode 1087.000000, reward total was -15.000000. running mean: -15.620061\n","resetting env. episode 1088.000000, reward total was -17.000000. running mean: -15.633860\n","resetting env. episode 1089.000000, reward total was -13.000000. running mean: -15.607522\n","resetting env. episode 1090.000000, reward total was -19.000000. running mean: -15.641446\n","resetting env. episode 1091.000000, reward total was -12.000000. running mean: -15.605032\n","resetting env. episode 1092.000000, reward total was -13.000000. running mean: -15.578982\n","resetting env. episode 1093.000000, reward total was -17.000000. running mean: -15.593192\n","resetting env. episode 1094.000000, reward total was -18.000000. running mean: -15.617260\n","resetting env. episode 1095.000000, reward total was -13.000000. running mean: -15.591087\n","resetting env. episode 1096.000000, reward total was -13.000000. running mean: -15.565176\n","resetting env. episode 1097.000000, reward total was -14.000000. running mean: -15.549525\n","resetting env. episode 1098.000000, reward total was -15.000000. running mean: -15.544029\n","resetting env. episode 1099.000000, reward total was -18.000000. running mean: -15.568589\n","resetting env. episode 1100.000000, reward total was -10.000000. running mean: -15.512903\n","resetting env. episode 1101.000000, reward total was -13.000000. running mean: -15.487774\n","resetting env. episode 1102.000000, reward total was -13.000000. running mean: -15.462896\n","resetting env. episode 1103.000000, reward total was -13.000000. running mean: -15.438267\n","resetting env. episode 1104.000000, reward total was -16.000000. running mean: -15.443885\n","resetting env. episode 1105.000000, reward total was -9.000000. running mean: -15.379446\n","resetting env. episode 1106.000000, reward total was -12.000000. running mean: -15.345651\n","resetting env. episode 1107.000000, reward total was -10.000000. running mean: -15.292195\n","resetting env. episode 1108.000000, reward total was -13.000000. running mean: -15.269273\n","resetting env. episode 1109.000000, reward total was -14.000000. running mean: -15.256580\n","resetting env. episode 1110.000000, reward total was -14.000000. running mean: -15.244014\n","resetting env. episode 1111.000000, reward total was -17.000000. running mean: -15.261574\n","resetting env. episode 1112.000000, reward total was -15.000000. running mean: -15.258959\n","resetting env. episode 1113.000000, reward total was -14.000000. running mean: -15.246369\n","resetting env. episode 1114.000000, reward total was -17.000000. running mean: -15.263905\n","resetting env. episode 1115.000000, reward total was -14.000000. running mean: -15.251266\n","resetting env. episode 1116.000000, reward total was -2.000000. running mean: -15.118754\n","resetting env. episode 1117.000000, reward total was -17.000000. running mean: -15.137566\n","resetting env. episode 1118.000000, reward total was -11.000000. running mean: -15.096190\n","resetting env. episode 1119.000000, reward total was -16.000000. running mean: -15.105228\n","resetting env. episode 1120.000000, reward total was -17.000000. running mean: -15.124176\n","resetting env. episode 1121.000000, reward total was -11.000000. running mean: -15.082934\n","resetting env. episode 1122.000000, reward total was -14.000000. running mean: -15.072105\n","resetting env. episode 1123.000000, reward total was -10.000000. running mean: -15.021384\n","resetting env. episode 1124.000000, reward total was -14.000000. running mean: -15.011170\n","resetting env. episode 1125.000000, reward total was -17.000000. running mean: -15.031058\n","resetting env. episode 1126.000000, reward total was -16.000000. running mean: -15.040748\n","resetting env. episode 1127.000000, reward total was -13.000000. running mean: -15.020340\n","resetting env. episode 1128.000000, reward total was -15.000000. running mean: -15.020137\n","resetting env. episode 1129.000000, reward total was -16.000000. running mean: -15.029936\n","resetting env. episode 1130.000000, reward total was -15.000000. running mean: -15.029636\n","resetting env. episode 1131.000000, reward total was -13.000000. running mean: -15.009340\n","resetting env. episode 1132.000000, reward total was -17.000000. running mean: -15.029247\n","resetting env. episode 1133.000000, reward total was -17.000000. running mean: -15.048954\n","resetting env. episode 1134.000000, reward total was -19.000000. running mean: -15.088465\n","resetting env. episode 1135.000000, reward total was -16.000000. running mean: -15.097580\n","resetting env. episode 1136.000000, reward total was -16.000000. running mean: -15.106604\n","resetting env. episode 1137.000000, reward total was -17.000000. running mean: -15.125538\n","resetting env. episode 1138.000000, reward total was -10.000000. running mean: -15.074283\n","resetting env. episode 1139.000000, reward total was -19.000000. running mean: -15.113540\n","resetting env. episode 1140.000000, reward total was -13.000000. running mean: -15.092404\n","resetting env. episode 1141.000000, reward total was -8.000000. running mean: -15.021480\n","resetting env. episode 1142.000000, reward total was -19.000000. running mean: -15.061266\n","resetting env. episode 1143.000000, reward total was -8.000000. running mean: -14.990653\n","resetting env. episode 1144.000000, reward total was -15.000000. running mean: -14.990746\n","resetting env. episode 1145.000000, reward total was -11.000000. running mean: -14.950839\n","resetting env. episode 1146.000000, reward total was -10.000000. running mean: -14.901331\n","resetting env. episode 1147.000000, reward total was -13.000000. running mean: -14.882317\n","resetting env. episode 1148.000000, reward total was -16.000000. running mean: -14.893494\n","resetting env. episode 1149.000000, reward total was -15.000000. running mean: -14.894559\n","resetting env. episode 1150.000000, reward total was -17.000000. running mean: -14.915614\n","resetting env. episode 1151.000000, reward total was -11.000000. running mean: -14.876457\n","resetting env. episode 1152.000000, reward total was -14.000000. running mean: -14.867693\n","resetting env. episode 1153.000000, reward total was -16.000000. running mean: -14.879016\n","resetting env. episode 1154.000000, reward total was -15.000000. running mean: -14.880226\n","resetting env. episode 1155.000000, reward total was -15.000000. running mean: -14.881423\n","resetting env. episode 1156.000000, reward total was -17.000000. running mean: -14.902609\n","resetting env. episode 1157.000000, reward total was -13.000000. running mean: -14.883583\n","resetting env. episode 1158.000000, reward total was -12.000000. running mean: -14.854747\n","resetting env. episode 1159.000000, reward total was -17.000000. running mean: -14.876200\n","resetting env. episode 1160.000000, reward total was -15.000000. running mean: -14.877438\n","resetting env. episode 1161.000000, reward total was -12.000000. running mean: -14.848663\n","resetting env. episode 1162.000000, reward total was -15.000000. running mean: -14.850177\n","resetting env. episode 1163.000000, reward total was -11.000000. running mean: -14.811675\n","resetting env. episode 1164.000000, reward total was -16.000000. running mean: -14.823558\n","resetting env. episode 1165.000000, reward total was -15.000000. running mean: -14.825323\n","resetting env. episode 1166.000000, reward total was -17.000000. running mean: -14.847069\n","resetting env. episode 1167.000000, reward total was -15.000000. running mean: -14.848599\n","resetting env. episode 1168.000000, reward total was -15.000000. running mean: -14.850113\n","resetting env. episode 1169.000000, reward total was -17.000000. running mean: -14.871612\n","resetting env. episode 1170.000000, reward total was -9.000000. running mean: -14.812896\n","resetting env. episode 1171.000000, reward total was -10.000000. running mean: -14.764767\n","resetting env. episode 1172.000000, reward total was -19.000000. running mean: -14.807119\n","resetting env. episode 1173.000000, reward total was -18.000000. running mean: -14.839048\n","resetting env. episode 1174.000000, reward total was -16.000000. running mean: -14.850657\n","resetting env. episode 1175.000000, reward total was -13.000000. running mean: -14.832151\n","resetting env. episode 1176.000000, reward total was -11.000000. running mean: -14.793829\n","resetting env. episode 1177.000000, reward total was -14.000000. running mean: -14.785891\n","resetting env. episode 1178.000000, reward total was -11.000000. running mean: -14.748032\n","resetting env. episode 1179.000000, reward total was -17.000000. running mean: -14.770552\n","resetting env. episode 1180.000000, reward total was -14.000000. running mean: -14.762846\n","resetting env. episode 1181.000000, reward total was -14.000000. running mean: -14.755218\n","resetting env. episode 1182.000000, reward total was -17.000000. running mean: -14.777666\n","resetting env. episode 1183.000000, reward total was -19.000000. running mean: -14.819889\n","resetting env. episode 1184.000000, reward total was -14.000000. running mean: -14.811690\n","resetting env. episode 1185.000000, reward total was -14.000000. running mean: -14.803573\n","resetting env. episode 1186.000000, reward total was -17.000000. running mean: -14.825537\n","resetting env. episode 1187.000000, reward total was -9.000000. running mean: -14.767282\n","resetting env. episode 1188.000000, reward total was -17.000000. running mean: -14.789609\n","resetting env. episode 1189.000000, reward total was -17.000000. running mean: -14.811713\n","resetting env. episode 1190.000000, reward total was -13.000000. running mean: -14.793596\n","resetting env. episode 1191.000000, reward total was -17.000000. running mean: -14.815660\n","resetting env. episode 1192.000000, reward total was -15.000000. running mean: -14.817503\n","resetting env. episode 1193.000000, reward total was -16.000000. running mean: -14.829328\n","resetting env. episode 1194.000000, reward total was -11.000000. running mean: -14.791035\n","resetting env. episode 1195.000000, reward total was -15.000000. running mean: -14.793125\n","resetting env. episode 1196.000000, reward total was -15.000000. running mean: -14.795193\n","resetting env. episode 1197.000000, reward total was -12.000000. running mean: -14.767242\n","resetting env. episode 1198.000000, reward total was -21.000000. running mean: -14.829569\n","resetting env. episode 1199.000000, reward total was -17.000000. running mean: -14.851273\n","resetting env. episode 1200.000000, reward total was -14.000000. running mean: -14.842761\n","resetting env. episode 1201.000000, reward total was -15.000000. running mean: -14.844333\n","resetting env. episode 1202.000000, reward total was -16.000000. running mean: -14.855890\n","resetting env. episode 1203.000000, reward total was -16.000000. running mean: -14.867331\n","resetting env. episode 1204.000000, reward total was -19.000000. running mean: -14.908658\n","resetting env. episode 1205.000000, reward total was 1.000000. running mean: -14.749571\n","resetting env. episode 1206.000000, reward total was -13.000000. running mean: -14.732075\n","resetting env. episode 1207.000000, reward total was -14.000000. running mean: -14.724755\n","resetting env. episode 1208.000000, reward total was -18.000000. running mean: -14.757507\n","resetting env. episode 1209.000000, reward total was -19.000000. running mean: -14.799932\n","resetting env. episode 1210.000000, reward total was -13.000000. running mean: -14.781933\n","resetting env. episode 1211.000000, reward total was -11.000000. running mean: -14.744113\n","resetting env. episode 1212.000000, reward total was -12.000000. running mean: -14.716672\n","resetting env. episode 1213.000000, reward total was -17.000000. running mean: -14.739505\n","resetting env. episode 1214.000000, reward total was -14.000000. running mean: -14.732110\n","resetting env. episode 1215.000000, reward total was -13.000000. running mean: -14.714789\n","resetting env. episode 1216.000000, reward total was -15.000000. running mean: -14.717641\n","resetting env. episode 1217.000000, reward total was -16.000000. running mean: -14.730465\n","resetting env. episode 1218.000000, reward total was -15.000000. running mean: -14.733160\n","resetting env. episode 1219.000000, reward total was -15.000000. running mean: -14.735829\n","resetting env. episode 1220.000000, reward total was -16.000000. running mean: -14.748470\n","resetting env. episode 1221.000000, reward total was -14.000000. running mean: -14.740986\n","resetting env. episode 1222.000000, reward total was -14.000000. running mean: -14.733576\n","resetting env. episode 1223.000000, reward total was -13.000000. running mean: -14.716240\n","resetting env. episode 1224.000000, reward total was -9.000000. running mean: -14.659078\n","resetting env. episode 1225.000000, reward total was -19.000000. running mean: -14.702487\n","resetting env. episode 1226.000000, reward total was -14.000000. running mean: -14.695462\n","resetting env. episode 1227.000000, reward total was -12.000000. running mean: -14.668507\n","resetting env. episode 1228.000000, reward total was -18.000000. running mean: -14.701822\n","resetting env. episode 1229.000000, reward total was -11.000000. running mean: -14.664804\n","resetting env. episode 1230.000000, reward total was -17.000000. running mean: -14.688156\n","resetting env. episode 1231.000000, reward total was -14.000000. running mean: -14.681275\n","resetting env. episode 1232.000000, reward total was -8.000000. running mean: -14.614462\n","resetting env. episode 1233.000000, reward total was -16.000000. running mean: -14.628317\n","resetting env. episode 1234.000000, reward total was -11.000000. running mean: -14.592034\n","resetting env. episode 1235.000000, reward total was -15.000000. running mean: -14.596114\n","resetting env. episode 1236.000000, reward total was -14.000000. running mean: -14.590152\n","resetting env. episode 1237.000000, reward total was -15.000000. running mean: -14.594251\n","resetting env. episode 1238.000000, reward total was -15.000000. running mean: -14.598308\n","resetting env. episode 1239.000000, reward total was -16.000000. running mean: -14.612325\n","resetting env. episode 1240.000000, reward total was -9.000000. running mean: -14.556202\n","resetting env. episode 1241.000000, reward total was -19.000000. running mean: -14.600640\n","resetting env. episode 1242.000000, reward total was -15.000000. running mean: -14.604634\n","resetting env. episode 1243.000000, reward total was -9.000000. running mean: -14.548587\n","resetting env. episode 1244.000000, reward total was -16.000000. running mean: -14.563101\n","resetting env. episode 1245.000000, reward total was -12.000000. running mean: -14.537470\n","resetting env. episode 1246.000000, reward total was -13.000000. running mean: -14.522096\n","resetting env. episode 1247.000000, reward total was -12.000000. running mean: -14.496875\n","resetting env. episode 1248.000000, reward total was -17.000000. running mean: -14.521906\n","resetting env. episode 1249.000000, reward total was -12.000000. running mean: -14.496687\n","resetting env. episode 1250.000000, reward total was -17.000000. running mean: -14.521720\n","resetting env. episode 1251.000000, reward total was -16.000000. running mean: -14.536503\n","resetting env. episode 1252.000000, reward total was -10.000000. running mean: -14.491138\n","resetting env. episode 1253.000000, reward total was -12.000000. running mean: -14.466227\n","resetting env. episode 1254.000000, reward total was -12.000000. running mean: -14.441564\n","resetting env. episode 1255.000000, reward total was -17.000000. running mean: -14.467149\n","resetting env. episode 1256.000000, reward total was -12.000000. running mean: -14.442477\n","resetting env. episode 1257.000000, reward total was -17.000000. running mean: -14.468052\n","resetting env. episode 1258.000000, reward total was -18.000000. running mean: -14.503372\n","resetting env. episode 1259.000000, reward total was -19.000000. running mean: -14.548338\n","resetting env. episode 1260.000000, reward total was -12.000000. running mean: -14.522855\n","resetting env. episode 1261.000000, reward total was -21.000000. running mean: -14.587626\n","resetting env. episode 1262.000000, reward total was -14.000000. running mean: -14.581750\n","resetting env. episode 1263.000000, reward total was -13.000000. running mean: -14.565932\n","resetting env. episode 1264.000000, reward total was -15.000000. running mean: -14.570273\n","resetting env. episode 1265.000000, reward total was -11.000000. running mean: -14.534570\n","resetting env. episode 1266.000000, reward total was -9.000000. running mean: -14.479225\n","resetting env. episode 1267.000000, reward total was -15.000000. running mean: -14.484432\n","resetting env. episode 1268.000000, reward total was -15.000000. running mean: -14.489588\n","resetting env. episode 1269.000000, reward total was -12.000000. running mean: -14.464692\n","resetting env. episode 1270.000000, reward total was -19.000000. running mean: -14.510045\n","resetting env. episode 1271.000000, reward total was -13.000000. running mean: -14.494945\n","resetting env. episode 1272.000000, reward total was -15.000000. running mean: -14.499995\n","resetting env. episode 1273.000000, reward total was -15.000000. running mean: -14.504995\n","resetting env. episode 1274.000000, reward total was -11.000000. running mean: -14.469945\n","resetting env. episode 1275.000000, reward total was -13.000000. running mean: -14.455246\n","resetting env. episode 1276.000000, reward total was -8.000000. running mean: -14.390694\n","resetting env. episode 1277.000000, reward total was -15.000000. running mean: -14.396787\n","resetting env. episode 1278.000000, reward total was -16.000000. running mean: -14.412819\n","resetting env. episode 1279.000000, reward total was -15.000000. running mean: -14.418691\n","resetting env. episode 1280.000000, reward total was -13.000000. running mean: -14.404504\n","resetting env. episode 1281.000000, reward total was -15.000000. running mean: -14.410459\n","resetting env. episode 1282.000000, reward total was -15.000000. running mean: -14.416354\n","resetting env. episode 1283.000000, reward total was -13.000000. running mean: -14.402191\n","resetting env. episode 1284.000000, reward total was -11.000000. running mean: -14.368169\n","resetting env. episode 1285.000000, reward total was -11.000000. running mean: -14.334487\n","resetting env. episode 1286.000000, reward total was -16.000000. running mean: -14.351142\n","resetting env. episode 1287.000000, reward total was -17.000000. running mean: -14.377631\n","resetting env. episode 1288.000000, reward total was -17.000000. running mean: -14.403854\n","resetting env. episode 1289.000000, reward total was -14.000000. running mean: -14.399816\n","resetting env. episode 1290.000000, reward total was -18.000000. running mean: -14.435818\n","resetting env. episode 1291.000000, reward total was -12.000000. running mean: -14.411459\n","resetting env. episode 1292.000000, reward total was -15.000000. running mean: -14.417345\n","resetting env. episode 1293.000000, reward total was -15.000000. running mean: -14.423171\n","resetting env. episode 1294.000000, reward total was -13.000000. running mean: -14.408940\n","resetting env. episode 1295.000000, reward total was -14.000000. running mean: -14.404850\n","resetting env. episode 1296.000000, reward total was -12.000000. running mean: -14.380802\n","resetting env. episode 1297.000000, reward total was -14.000000. running mean: -14.376994\n","resetting env. episode 1298.000000, reward total was -13.000000. running mean: -14.363224\n","resetting env. episode 1299.000000, reward total was -17.000000. running mean: -14.389592\n","resetting env. episode 1300.000000, reward total was -12.000000. running mean: -14.365696\n","resetting env. episode 1301.000000, reward total was -18.000000. running mean: -14.402039\n","resetting env. episode 1302.000000, reward total was -12.000000. running mean: -14.378018\n","resetting env. episode 1303.000000, reward total was -16.000000. running mean: -14.394238\n","resetting env. episode 1304.000000, reward total was -12.000000. running mean: -14.370296\n","resetting env. episode 1305.000000, reward total was -10.000000. running mean: -14.326593\n","resetting env. episode 1306.000000, reward total was -16.000000. running mean: -14.343327\n","resetting env. episode 1307.000000, reward total was -16.000000. running mean: -14.359894\n","resetting env. episode 1308.000000, reward total was -13.000000. running mean: -14.346295\n","resetting env. episode 1309.000000, reward total was -11.000000. running mean: -14.312832\n","resetting env. episode 1310.000000, reward total was -15.000000. running mean: -14.319703\n","resetting env. episode 1311.000000, reward total was -9.000000. running mean: -14.266506\n","resetting env. episode 1312.000000, reward total was -18.000000. running mean: -14.303841\n","resetting env. episode 1313.000000, reward total was -12.000000. running mean: -14.280803\n","resetting env. episode 1314.000000, reward total was -18.000000. running mean: -14.317995\n","resetting env. episode 1315.000000, reward total was -16.000000. running mean: -14.334815\n","resetting env. episode 1316.000000, reward total was -11.000000. running mean: -14.301467\n","resetting env. episode 1317.000000, reward total was -15.000000. running mean: -14.308452\n","resetting env. episode 1318.000000, reward total was -18.000000. running mean: -14.345368\n","resetting env. episode 1319.000000, reward total was -17.000000. running mean: -14.371914\n","resetting env. episode 1320.000000, reward total was -13.000000. running mean: -14.358195\n","resetting env. episode 1321.000000, reward total was -18.000000. running mean: -14.394613\n","resetting env. episode 1322.000000, reward total was -11.000000. running mean: -14.360667\n","resetting env. episode 1323.000000, reward total was -18.000000. running mean: -14.397060\n","resetting env. episode 1324.000000, reward total was -17.000000. running mean: -14.423089\n","resetting env. episode 1325.000000, reward total was -12.000000. running mean: -14.398859\n","resetting env. episode 1326.000000, reward total was -15.000000. running mean: -14.404870\n","resetting env. episode 1327.000000, reward total was -15.000000. running mean: -14.410821\n","resetting env. episode 1328.000000, reward total was -16.000000. running mean: -14.426713\n","resetting env. episode 1329.000000, reward total was -15.000000. running mean: -14.432446\n","resetting env. episode 1330.000000, reward total was -16.000000. running mean: -14.448121\n","resetting env. episode 1331.000000, reward total was -11.000000. running mean: -14.413640\n","resetting env. episode 1332.000000, reward total was -13.000000. running mean: -14.399504\n","resetting env. episode 1333.000000, reward total was -19.000000. running mean: -14.445509\n","resetting env. episode 1334.000000, reward total was -12.000000. running mean: -14.421054\n","resetting env. episode 1335.000000, reward total was -19.000000. running mean: -14.466843\n","resetting env. episode 1336.000000, reward total was -12.000000. running mean: -14.442175\n","resetting env. episode 1337.000000, reward total was -14.000000. running mean: -14.437753\n","resetting env. episode 1338.000000, reward total was -14.000000. running mean: -14.433375\n","resetting env. episode 1339.000000, reward total was -14.000000. running mean: -14.429042\n","resetting env. episode 1340.000000, reward total was -14.000000. running mean: -14.424751\n","resetting env. episode 1341.000000, reward total was -16.000000. running mean: -14.440504\n","resetting env. episode 1342.000000, reward total was -9.000000. running mean: -14.386099\n","resetting env. episode 1343.000000, reward total was -14.000000. running mean: -14.382238\n","resetting env. episode 1344.000000, reward total was -18.000000. running mean: -14.418415\n","resetting env. episode 1345.000000, reward total was -11.000000. running mean: -14.384231\n","resetting env. episode 1346.000000, reward total was -17.000000. running mean: -14.410389\n","resetting env. episode 1347.000000, reward total was -11.000000. running mean: -14.376285\n","resetting env. episode 1348.000000, reward total was -16.000000. running mean: -14.392522\n","resetting env. episode 1349.000000, reward total was -17.000000. running mean: -14.418597\n","resetting env. episode 1350.000000, reward total was -12.000000. running mean: -14.394411\n","resetting env. episode 1351.000000, reward total was -11.000000. running mean: -14.360467\n","resetting env. episode 1352.000000, reward total was -19.000000. running mean: -14.406862\n","resetting env. episode 1353.000000, reward total was -13.000000. running mean: -14.392794\n","resetting env. episode 1354.000000, reward total was -7.000000. running mean: -14.318866\n","resetting env. episode 1355.000000, reward total was -11.000000. running mean: -14.285677\n","resetting env. episode 1356.000000, reward total was -14.000000. running mean: -14.282820\n","resetting env. episode 1357.000000, reward total was -17.000000. running mean: -14.309992\n","resetting env. episode 1358.000000, reward total was -14.000000. running mean: -14.306892\n","resetting env. episode 1359.000000, reward total was -11.000000. running mean: -14.273823\n","resetting env. episode 1360.000000, reward total was -12.000000. running mean: -14.251085\n","resetting env. episode 1361.000000, reward total was -12.000000. running mean: -14.228574\n","resetting env. episode 1362.000000, reward total was -9.000000. running mean: -14.176288\n","resetting env. episode 1363.000000, reward total was -13.000000. running mean: -14.164525\n","resetting env. episode 1364.000000, reward total was -16.000000. running mean: -14.182880\n","resetting env. episode 1365.000000, reward total was -15.000000. running mean: -14.191051\n","resetting env. episode 1366.000000, reward total was -6.000000. running mean: -14.109141\n","resetting env. episode 1367.000000, reward total was -13.000000. running mean: -14.098049\n","resetting env. episode 1368.000000, reward total was -12.000000. running mean: -14.077069\n","resetting env. episode 1369.000000, reward total was -16.000000. running mean: -14.096298\n","resetting env. episode 1370.000000, reward total was -13.000000. running mean: -14.085335\n","resetting env. episode 1371.000000, reward total was -13.000000. running mean: -14.074482\n","resetting env. episode 1372.000000, reward total was -15.000000. running mean: -14.083737\n","resetting env. episode 1373.000000, reward total was -8.000000. running mean: -14.022900\n","resetting env. episode 1374.000000, reward total was -13.000000. running mean: -14.012671\n","resetting env. episode 1375.000000, reward total was -6.000000. running mean: -13.932544\n","resetting env. episode 1376.000000, reward total was -10.000000. running mean: -13.893219\n","resetting env. episode 1377.000000, reward total was -16.000000. running mean: -13.914286\n","resetting env. episode 1378.000000, reward total was -19.000000. running mean: -13.965144\n","resetting env. episode 1379.000000, reward total was -14.000000. running mean: -13.965492\n","resetting env. episode 1380.000000, reward total was -17.000000. running mean: -13.995837\n","resetting env. episode 1381.000000, reward total was -17.000000. running mean: -14.025879\n","resetting env. episode 1382.000000, reward total was -13.000000. running mean: -14.015620\n","resetting env. episode 1383.000000, reward total was -13.000000. running mean: -14.005464\n","resetting env. episode 1384.000000, reward total was -12.000000. running mean: -13.985409\n","resetting env. episode 1385.000000, reward total was -9.000000. running mean: -13.935555\n","resetting env. episode 1386.000000, reward total was -19.000000. running mean: -13.986200\n","resetting env. episode 1387.000000, reward total was -14.000000. running mean: -13.986338\n","resetting env. episode 1388.000000, reward total was -14.000000. running mean: -13.986474\n","resetting env. episode 1389.000000, reward total was -10.000000. running mean: -13.946609\n","resetting env. episode 1390.000000, reward total was -15.000000. running mean: -13.957143\n","resetting env. episode 1391.000000, reward total was -15.000000. running mean: -13.967572\n","resetting env. episode 1392.000000, reward total was -9.000000. running mean: -13.917896\n","resetting env. episode 1393.000000, reward total was -16.000000. running mean: -13.938717\n","resetting env. episode 1394.000000, reward total was -9.000000. running mean: -13.889330\n","resetting env. episode 1395.000000, reward total was -10.000000. running mean: -13.850437\n","resetting env. episode 1396.000000, reward total was -13.000000. running mean: -13.841932\n","resetting env. episode 1397.000000, reward total was -16.000000. running mean: -13.863513\n","resetting env. episode 1398.000000, reward total was -9.000000. running mean: -13.814878\n","resetting env. episode 1399.000000, reward total was -17.000000. running mean: -13.846729\n","resetting env. episode 1400.000000, reward total was -15.000000. running mean: -13.858262\n","resetting env. episode 1401.000000, reward total was -17.000000. running mean: -13.889679\n","resetting env. episode 1402.000000, reward total was -11.000000. running mean: -13.860782\n","resetting env. episode 1403.000000, reward total was -15.000000. running mean: -13.872175\n","resetting env. episode 1404.000000, reward total was -13.000000. running mean: -13.863453\n","resetting env. episode 1405.000000, reward total was -13.000000. running mean: -13.854818\n","resetting env. episode 1406.000000, reward total was -9.000000. running mean: -13.806270\n","resetting env. episode 1407.000000, reward total was -17.000000. running mean: -13.838207\n","resetting env. episode 1408.000000, reward total was -12.000000. running mean: -13.819825\n","resetting env. episode 1409.000000, reward total was -17.000000. running mean: -13.851627\n","resetting env. episode 1410.000000, reward total was -16.000000. running mean: -13.873111\n","resetting env. episode 1411.000000, reward total was -15.000000. running mean: -13.884380\n","resetting env. episode 1412.000000, reward total was -16.000000. running mean: -13.905536\n","resetting env. episode 1413.000000, reward total was -12.000000. running mean: -13.886481\n","resetting env. episode 1414.000000, reward total was -18.000000. running mean: -13.927616\n","resetting env. episode 1415.000000, reward total was -13.000000. running mean: -13.918340\n","resetting env. episode 1416.000000, reward total was -12.000000. running mean: -13.899156\n","resetting env. episode 1417.000000, reward total was -14.000000. running mean: -13.900165\n","resetting env. episode 1418.000000, reward total was -16.000000. running mean: -13.921163\n","resetting env. episode 1419.000000, reward total was -14.000000. running mean: -13.921951\n","resetting env. episode 1420.000000, reward total was -13.000000. running mean: -13.912732\n","resetting env. episode 1421.000000, reward total was -9.000000. running mean: -13.863605\n","resetting env. episode 1422.000000, reward total was -11.000000. running mean: -13.834969\n","resetting env. episode 1423.000000, reward total was -18.000000. running mean: -13.876619\n","resetting env. episode 1424.000000, reward total was -13.000000. running mean: -13.867853\n","resetting env. episode 1425.000000, reward total was -12.000000. running mean: -13.849174\n","resetting env. episode 1426.000000, reward total was -13.000000. running mean: -13.840682\n","resetting env. episode 1427.000000, reward total was -15.000000. running mean: -13.852276\n","resetting env. episode 1428.000000, reward total was -17.000000. running mean: -13.883753\n","resetting env. episode 1429.000000, reward total was -11.000000. running mean: -13.854915\n","resetting env. episode 1430.000000, reward total was -14.000000. running mean: -13.856366\n","resetting env. episode 1431.000000, reward total was -13.000000. running mean: -13.847802\n","resetting env. episode 1432.000000, reward total was -15.000000. running mean: -13.859324\n","resetting env. episode 1433.000000, reward total was -15.000000. running mean: -13.870731\n","resetting env. episode 1434.000000, reward total was -14.000000. running mean: -13.872024\n","resetting env. episode 1435.000000, reward total was -5.000000. running mean: -13.783304\n","resetting env. episode 1436.000000, reward total was -15.000000. running mean: -13.795471\n","resetting env. episode 1437.000000, reward total was -14.000000. running mean: -13.797516\n","resetting env. episode 1438.000000, reward total was -13.000000. running mean: -13.789541\n","resetting env. episode 1439.000000, reward total was -15.000000. running mean: -13.801645\n","resetting env. episode 1440.000000, reward total was -11.000000. running mean: -13.773629\n","resetting env. episode 1441.000000, reward total was -12.000000. running mean: -13.755893\n","resetting env. episode 1442.000000, reward total was -18.000000. running mean: -13.798334\n","resetting env. episode 1443.000000, reward total was -10.000000. running mean: -13.760350\n","resetting env. episode 1444.000000, reward total was -16.000000. running mean: -13.782747\n","resetting env. episode 1445.000000, reward total was -14.000000. running mean: -13.784919\n","resetting env. episode 1446.000000, reward total was -15.000000. running mean: -13.797070\n","resetting env. episode 1447.000000, reward total was -14.000000. running mean: -13.799099\n","resetting env. episode 1448.000000, reward total was -11.000000. running mean: -13.771108\n","resetting env. episode 1449.000000, reward total was -15.000000. running mean: -13.783397\n","resetting env. episode 1450.000000, reward total was -5.000000. running mean: -13.695563\n","resetting env. episode 1451.000000, reward total was -12.000000. running mean: -13.678608\n","resetting env. episode 1452.000000, reward total was -5.000000. running mean: -13.591822\n","resetting env. episode 1453.000000, reward total was -12.000000. running mean: -13.575903\n","resetting env. episode 1454.000000, reward total was -11.000000. running mean: -13.550144\n","resetting env. episode 1455.000000, reward total was -12.000000. running mean: -13.534643\n","resetting env. episode 1456.000000, reward total was -11.000000. running mean: -13.509297\n","resetting env. episode 1457.000000, reward total was -11.000000. running mean: -13.484204\n","resetting env. episode 1458.000000, reward total was -16.000000. running mean: -13.509362\n","resetting env. episode 1459.000000, reward total was -13.000000. running mean: -13.504268\n","resetting env. episode 1460.000000, reward total was -17.000000. running mean: -13.539225\n","resetting env. episode 1461.000000, reward total was -12.000000. running mean: -13.523833\n","resetting env. episode 1462.000000, reward total was -13.000000. running mean: -13.518595\n","resetting env. episode 1463.000000, reward total was -12.000000. running mean: -13.503409\n","resetting env. episode 1464.000000, reward total was -5.000000. running mean: -13.418375\n","resetting env. episode 1465.000000, reward total was -7.000000. running mean: -13.354191\n","resetting env. episode 1466.000000, reward total was -10.000000. running mean: -13.320649\n","resetting env. episode 1467.000000, reward total was -9.000000. running mean: -13.277443\n","resetting env. episode 1468.000000, reward total was -15.000000. running mean: -13.294668\n","resetting env. episode 1469.000000, reward total was -18.000000. running mean: -13.341721\n","resetting env. episode 1470.000000, reward total was -15.000000. running mean: -13.358304\n","resetting env. episode 1471.000000, reward total was -12.000000. running mean: -13.344721\n","resetting env. episode 1472.000000, reward total was -16.000000. running mean: -13.371274\n","resetting env. episode 1473.000000, reward total was -15.000000. running mean: -13.387561\n","resetting env. episode 1474.000000, reward total was -15.000000. running mean: -13.403686\n","resetting env. episode 1475.000000, reward total was -14.000000. running mean: -13.409649\n","resetting env. episode 1476.000000, reward total was -5.000000. running mean: -13.325552\n","resetting env. episode 1477.000000, reward total was -13.000000. running mean: -13.322297\n","resetting env. episode 1478.000000, reward total was -11.000000. running mean: -13.299074\n","resetting env. episode 1479.000000, reward total was -13.000000. running mean: -13.296083\n","resetting env. episode 1480.000000, reward total was -10.000000. running mean: -13.263122\n","resetting env. episode 1481.000000, reward total was -6.000000. running mean: -13.190491\n","resetting env. episode 1482.000000, reward total was -14.000000. running mean: -13.198586\n","resetting env. episode 1483.000000, reward total was -14.000000. running mean: -13.206600\n","resetting env. episode 1484.000000, reward total was -12.000000. running mean: -13.194534\n","resetting env. episode 1485.000000, reward total was -15.000000. running mean: -13.212589\n","resetting env. episode 1486.000000, reward total was -11.000000. running mean: -13.190463\n","resetting env. episode 1487.000000, reward total was -17.000000. running mean: -13.228558\n","resetting env. episode 1488.000000, reward total was -13.000000. running mean: -13.226273\n","resetting env. episode 1489.000000, reward total was -14.000000. running mean: -13.234010\n","resetting env. episode 1490.000000, reward total was -14.000000. running mean: -13.241670\n","resetting env. episode 1491.000000, reward total was -13.000000. running mean: -13.239253\n","resetting env. episode 1492.000000, reward total was -11.000000. running mean: -13.216861\n","resetting env. episode 1493.000000, reward total was -11.000000. running mean: -13.194692\n","resetting env. episode 1494.000000, reward total was -14.000000. running mean: -13.202745\n","resetting env. episode 1495.000000, reward total was -10.000000. running mean: -13.170718\n","resetting env. episode 1496.000000, reward total was -13.000000. running mean: -13.169011\n","resetting env. episode 1497.000000, reward total was -15.000000. running mean: -13.187320\n","resetting env. episode 1498.000000, reward total was -5.000000. running mean: -13.105447\n","resetting env. episode 1499.000000, reward total was -12.000000. running mean: -13.094393\n","resetting env. episode 1500.000000, reward total was -15.000000. running mean: -13.113449\n","resetting env. episode 1501.000000, reward total was -11.000000. running mean: -13.092314\n","resetting env. episode 1502.000000, reward total was -15.000000. running mean: -13.111391\n","resetting env. episode 1503.000000, reward total was -17.000000. running mean: -13.150277\n","resetting env. episode 1504.000000, reward total was -13.000000. running mean: -13.148775\n","resetting env. episode 1505.000000, reward total was -18.000000. running mean: -13.197287\n","resetting env. episode 1506.000000, reward total was -14.000000. running mean: -13.205314\n","resetting env. episode 1507.000000, reward total was -11.000000. running mean: -13.183261\n","resetting env. episode 1508.000000, reward total was -10.000000. running mean: -13.151428\n","resetting env. episode 1509.000000, reward total was -9.000000. running mean: -13.109914\n","resetting env. episode 1510.000000, reward total was -18.000000. running mean: -13.158815\n","resetting env. episode 1511.000000, reward total was -17.000000. running mean: -13.197227\n","resetting env. episode 1512.000000, reward total was -10.000000. running mean: -13.165254\n","resetting env. episode 1513.000000, reward total was -14.000000. running mean: -13.173602\n","resetting env. episode 1514.000000, reward total was -9.000000. running mean: -13.131866\n","resetting env. episode 1515.000000, reward total was -12.000000. running mean: -13.120547\n","resetting env. episode 1516.000000, reward total was -9.000000. running mean: -13.079342\n","resetting env. episode 1517.000000, reward total was -17.000000. running mean: -13.118548\n","resetting env. episode 1518.000000, reward total was -8.000000. running mean: -13.067363\n","resetting env. episode 1519.000000, reward total was -15.000000. running mean: -13.086689\n","resetting env. episode 1520.000000, reward total was -5.000000. running mean: -13.005822\n","resetting env. episode 1521.000000, reward total was -19.000000. running mean: -13.065764\n","resetting env. episode 1522.000000, reward total was -12.000000. running mean: -13.055106\n","resetting env. episode 1523.000000, reward total was -14.000000. running mean: -13.064555\n","resetting env. episode 1524.000000, reward total was -8.000000. running mean: -13.013910\n","resetting env. episode 1525.000000, reward total was -7.000000. running mean: -12.953771\n","resetting env. episode 1526.000000, reward total was -11.000000. running mean: -12.934233\n","resetting env. episode 1527.000000, reward total was -14.000000. running mean: -12.944891\n","resetting env. episode 1528.000000, reward total was -9.000000. running mean: -12.905442\n","resetting env. episode 1529.000000, reward total was -15.000000. running mean: -12.926387\n","resetting env. episode 1530.000000, reward total was -14.000000. running mean: -12.937123\n","resetting env. episode 1531.000000, reward total was -14.000000. running mean: -12.947752\n","resetting env. episode 1532.000000, reward total was -14.000000. running mean: -12.958275\n","resetting env. episode 1533.000000, reward total was -10.000000. running mean: -12.928692\n","resetting env. episode 1534.000000, reward total was -14.000000. running mean: -12.939405\n","resetting env. episode 1535.000000, reward total was -13.000000. running mean: -12.940011\n","resetting env. episode 1536.000000, reward total was -9.000000. running mean: -12.900611\n","resetting env. episode 1537.000000, reward total was -13.000000. running mean: -12.901605\n","resetting env. episode 1538.000000, reward total was -11.000000. running mean: -12.882589\n","resetting env. episode 1539.000000, reward total was -17.000000. running mean: -12.923763\n","resetting env. episode 1540.000000, reward total was -16.000000. running mean: -12.954525\n","resetting env. episode 1541.000000, reward total was -13.000000. running mean: -12.954980\n","resetting env. episode 1542.000000, reward total was -13.000000. running mean: -12.955430\n","resetting env. episode 1543.000000, reward total was -16.000000. running mean: -12.985876\n","resetting env. episode 1544.000000, reward total was -9.000000. running mean: -12.946017\n","resetting env. episode 1545.000000, reward total was -10.000000. running mean: -12.916557\n","resetting env. episode 1546.000000, reward total was -18.000000. running mean: -12.967391\n","resetting env. episode 1547.000000, reward total was -15.000000. running mean: -12.987717\n","resetting env. episode 1548.000000, reward total was -7.000000. running mean: -12.927840\n","resetting env. episode 1549.000000, reward total was -17.000000. running mean: -12.968562\n","resetting env. episode 1550.000000, reward total was -13.000000. running mean: -12.968876\n","resetting env. episode 1551.000000, reward total was -15.000000. running mean: -12.989187\n","resetting env. episode 1552.000000, reward total was -11.000000. running mean: -12.969296\n","resetting env. episode 1553.000000, reward total was -12.000000. running mean: -12.959603\n","resetting env. episode 1554.000000, reward total was -15.000000. running mean: -12.980007\n","resetting env. episode 1555.000000, reward total was 1.000000. running mean: -12.840207\n","resetting env. episode 1556.000000, reward total was -6.000000. running mean: -12.771804\n","resetting env. episode 1557.000000, reward total was -14.000000. running mean: -12.784086\n","resetting env. episode 1558.000000, reward total was -10.000000. running mean: -12.756246\n","resetting env. episode 1559.000000, reward total was -11.000000. running mean: -12.738683\n","resetting env. episode 1560.000000, reward total was -7.000000. running mean: -12.681296\n","resetting env. episode 1561.000000, reward total was -16.000000. running mean: -12.714483\n","resetting env. episode 1562.000000, reward total was -12.000000. running mean: -12.707338\n","resetting env. episode 1563.000000, reward total was -9.000000. running mean: -12.670265\n","resetting env. episode 1564.000000, reward total was -13.000000. running mean: -12.673562\n","resetting env. episode 1565.000000, reward total was -14.000000. running mean: -12.686827\n","resetting env. episode 1566.000000, reward total was -7.000000. running mean: -12.629959\n","resetting env. episode 1567.000000, reward total was -15.000000. running mean: -12.653659\n","resetting env. episode 1568.000000, reward total was -15.000000. running mean: -12.677122\n","resetting env. episode 1569.000000, reward total was -13.000000. running mean: -12.680351\n","resetting env. episode 1570.000000, reward total was -9.000000. running mean: -12.643548\n","resetting env. episode 1571.000000, reward total was -8.000000. running mean: -12.597112\n","resetting env. episode 1572.000000, reward total was -9.000000. running mean: -12.561141\n","resetting env. episode 1573.000000, reward total was -12.000000. running mean: -12.555530\n","resetting env. episode 1574.000000, reward total was -10.000000. running mean: -12.529974\n","resetting env. episode 1575.000000, reward total was -11.000000. running mean: -12.514675\n","resetting env. episode 1576.000000, reward total was -9.000000. running mean: -12.479528\n","resetting env. episode 1577.000000, reward total was -10.000000. running mean: -12.454733\n","resetting env. episode 1578.000000, reward total was -11.000000. running mean: -12.440185\n","resetting env. episode 1579.000000, reward total was -9.000000. running mean: -12.405783\n","resetting env. episode 1580.000000, reward total was -15.000000. running mean: -12.431726\n","resetting env. episode 1581.000000, reward total was -7.000000. running mean: -12.377408\n","resetting env. episode 1582.000000, reward total was -8.000000. running mean: -12.333634\n","resetting env. episode 1583.000000, reward total was -16.000000. running mean: -12.370298\n","resetting env. episode 1584.000000, reward total was -13.000000. running mean: -12.376595\n","resetting env. episode 1585.000000, reward total was -12.000000. running mean: -12.372829\n","resetting env. episode 1586.000000, reward total was -15.000000. running mean: -12.399101\n","resetting env. episode 1587.000000, reward total was -9.000000. running mean: -12.365110\n","resetting env. episode 1588.000000, reward total was -14.000000. running mean: -12.381459\n","resetting env. episode 1589.000000, reward total was -12.000000. running mean: -12.377644\n","resetting env. episode 1590.000000, reward total was -9.000000. running mean: -12.343868\n","resetting env. episode 1591.000000, reward total was -12.000000. running mean: -12.340429\n","resetting env. episode 1592.000000, reward total was -14.000000. running mean: -12.357025\n","resetting env. episode 1593.000000, reward total was -13.000000. running mean: -12.363454\n","resetting env. episode 1594.000000, reward total was -7.000000. running mean: -12.309820\n","resetting env. episode 1595.000000, reward total was -7.000000. running mean: -12.256722\n","resetting env. episode 1596.000000, reward total was -13.000000. running mean: -12.264154\n","resetting env. episode 1597.000000, reward total was -11.000000. running mean: -12.251513\n","resetting env. episode 1598.000000, reward total was -12.000000. running mean: -12.248998\n","resetting env. episode 1599.000000, reward total was -6.000000. running mean: -12.186508\n","resetting env. episode 1600.000000, reward total was -10.000000. running mean: -12.164643\n","resetting env. episode 1601.000000, reward total was -10.000000. running mean: -12.142996\n","resetting env. episode 1602.000000, reward total was -13.000000. running mean: -12.151566\n","resetting env. episode 1603.000000, reward total was -10.000000. running mean: -12.130051\n","resetting env. episode 1604.000000, reward total was -12.000000. running mean: -12.128750\n","resetting env. episode 1605.000000, reward total was -11.000000. running mean: -12.117463\n","resetting env. episode 1606.000000, reward total was -15.000000. running mean: -12.146288\n","resetting env. episode 1607.000000, reward total was -12.000000. running mean: -12.144825\n","resetting env. episode 1608.000000, reward total was -12.000000. running mean: -12.143377\n","resetting env. episode 1609.000000, reward total was -11.000000. running mean: -12.131943\n","resetting env. episode 1610.000000, reward total was -12.000000. running mean: -12.130624\n","resetting env. episode 1611.000000, reward total was -14.000000. running mean: -12.149317\n","resetting env. episode 1612.000000, reward total was -9.000000. running mean: -12.117824\n","resetting env. episode 1613.000000, reward total was -7.000000. running mean: -12.066646\n","resetting env. episode 1614.000000, reward total was -3.000000. running mean: -11.975980\n","resetting env. episode 1615.000000, reward total was -13.000000. running mean: -11.986220\n","resetting env. episode 1616.000000, reward total was -4.000000. running mean: -11.906358\n","resetting env. episode 1617.000000, reward total was -15.000000. running mean: -11.937294\n","resetting env. episode 1618.000000, reward total was -12.000000. running mean: -11.937921\n","resetting env. episode 1619.000000, reward total was -7.000000. running mean: -11.888542\n","resetting env. episode 1620.000000, reward total was -12.000000. running mean: -11.889656\n","resetting env. episode 1621.000000, reward total was -11.000000. running mean: -11.880760\n","resetting env. episode 1622.000000, reward total was -15.000000. running mean: -11.911952\n","resetting env. episode 1623.000000, reward total was -11.000000. running mean: -11.902833\n","resetting env. episode 1624.000000, reward total was -6.000000. running mean: -11.843804\n","resetting env. episode 1625.000000, reward total was -8.000000. running mean: -11.805366\n","resetting env. episode 1626.000000, reward total was -13.000000. running mean: -11.817313\n","resetting env. episode 1627.000000, reward total was -12.000000. running mean: -11.819140\n","resetting env. episode 1628.000000, reward total was -9.000000. running mean: -11.790948\n","resetting env. episode 1629.000000, reward total was -4.000000. running mean: -11.713039\n","resetting env. episode 1630.000000, reward total was -13.000000. running mean: -11.725908\n","resetting env. episode 1631.000000, reward total was -11.000000. running mean: -11.718649\n","resetting env. episode 1632.000000, reward total was -11.000000. running mean: -11.711463\n","resetting env. episode 1633.000000, reward total was -7.000000. running mean: -11.664348\n","resetting env. episode 1634.000000, reward total was -15.000000. running mean: -11.697705\n","resetting env. episode 1635.000000, reward total was -12.000000. running mean: -11.700728\n","resetting env. episode 1636.000000, reward total was -11.000000. running mean: -11.693720\n","resetting env. episode 1637.000000, reward total was -11.000000. running mean: -11.686783\n","resetting env. episode 1638.000000, reward total was -7.000000. running mean: -11.639915\n","resetting env. episode 1639.000000, reward total was -7.000000. running mean: -11.593516\n","resetting env. episode 1640.000000, reward total was -13.000000. running mean: -11.607581\n","resetting env. episode 1641.000000, reward total was -7.000000. running mean: -11.561505\n","resetting env. episode 1642.000000, reward total was -16.000000. running mean: -11.605890\n","resetting env. episode 1643.000000, reward total was -6.000000. running mean: -11.549831\n","resetting env. episode 1644.000000, reward total was -17.000000. running mean: -11.604333\n","resetting env. episode 1645.000000, reward total was -9.000000. running mean: -11.578290\n","resetting env. episode 1646.000000, reward total was -16.000000. running mean: -11.622507\n","resetting env. episode 1647.000000, reward total was -11.000000. running mean: -11.616282\n","resetting env. episode 1648.000000, reward total was -14.000000. running mean: -11.640119\n","resetting env. episode 1649.000000, reward total was -14.000000. running mean: -11.663718\n","resetting env. episode 1650.000000, reward total was -13.000000. running mean: -11.677080\n","resetting env. episode 1651.000000, reward total was -15.000000. running mean: -11.710310\n","resetting env. episode 1652.000000, reward total was -19.000000. running mean: -11.783206\n","resetting env. episode 1653.000000, reward total was -19.000000. running mean: -11.855374\n","resetting env. episode 1654.000000, reward total was -14.000000. running mean: -11.876821\n","resetting env. episode 1655.000000, reward total was -12.000000. running mean: -11.878052\n","resetting env. episode 1656.000000, reward total was -10.000000. running mean: -11.859272\n","resetting env. episode 1657.000000, reward total was -13.000000. running mean: -11.870679\n","resetting env. episode 1658.000000, reward total was -9.000000. running mean: -11.841972\n","resetting env. episode 1659.000000, reward total was -9.000000. running mean: -11.813553\n","resetting env. episode 1660.000000, reward total was -10.000000. running mean: -11.795417\n","resetting env. episode 1661.000000, reward total was -13.000000. running mean: -11.807463\n","resetting env. episode 1662.000000, reward total was -12.000000. running mean: -11.809388\n","resetting env. episode 1663.000000, reward total was -18.000000. running mean: -11.871294\n","resetting env. episode 1664.000000, reward total was -16.000000. running mean: -11.912582\n","resetting env. episode 1665.000000, reward total was -11.000000. running mean: -11.903456\n","resetting env. episode 1666.000000, reward total was -13.000000. running mean: -11.914421\n","resetting env. episode 1667.000000, reward total was -17.000000. running mean: -11.965277\n","resetting env. episode 1668.000000, reward total was -15.000000. running mean: -11.995624\n","resetting env. episode 1669.000000, reward total was -13.000000. running mean: -12.005668\n","resetting env. episode 1670.000000, reward total was -13.000000. running mean: -12.015611\n","resetting env. episode 1671.000000, reward total was -15.000000. running mean: -12.045455\n","resetting env. episode 1672.000000, reward total was -13.000000. running mean: -12.055001\n","resetting env. episode 1673.000000, reward total was -14.000000. running mean: -12.074451\n","resetting env. episode 1674.000000, reward total was -9.000000. running mean: -12.043706\n","resetting env. episode 1675.000000, reward total was -5.000000. running mean: -11.973269\n","resetting env. episode 1676.000000, reward total was -10.000000. running mean: -11.953536\n","resetting env. episode 1677.000000, reward total was -15.000000. running mean: -11.984001\n","resetting env. episode 1678.000000, reward total was -10.000000. running mean: -11.964161\n","resetting env. episode 1679.000000, reward total was -14.000000. running mean: -11.984519\n","resetting env. episode 1680.000000, reward total was -7.000000. running mean: -11.934674\n","resetting env. episode 1681.000000, reward total was -17.000000. running mean: -11.985327\n","resetting env. episode 1682.000000, reward total was -12.000000. running mean: -11.985474\n","resetting env. episode 1683.000000, reward total was -14.000000. running mean: -12.005619\n","resetting env. episode 1684.000000, reward total was -9.000000. running mean: -11.975563\n","resetting env. episode 1685.000000, reward total was -6.000000. running mean: -11.915808\n","resetting env. episode 1686.000000, reward total was -17.000000. running mean: -11.966650\n","resetting env. episode 1687.000000, reward total was -19.000000. running mean: -12.036983\n","resetting env. episode 1688.000000, reward total was -13.000000. running mean: -12.046613\n","resetting env. episode 1689.000000, reward total was -10.000000. running mean: -12.026147\n","resetting env. episode 1690.000000, reward total was -10.000000. running mean: -12.005886\n","resetting env. episode 1691.000000, reward total was -4.000000. running mean: -11.925827\n","resetting env. episode 1692.000000, reward total was -13.000000. running mean: -11.936568\n","resetting env. episode 1693.000000, reward total was -11.000000. running mean: -11.927203\n","resetting env. episode 1694.000000, reward total was -16.000000. running mean: -11.967931\n","resetting env. episode 1695.000000, reward total was -19.000000. running mean: -12.038251\n","resetting env. episode 1696.000000, reward total was -14.000000. running mean: -12.057869\n","resetting env. episode 1697.000000, reward total was -13.000000. running mean: -12.067290\n","resetting env. episode 1698.000000, reward total was -10.000000. running mean: -12.046617\n","resetting env. episode 1699.000000, reward total was -10.000000. running mean: -12.026151\n","resetting env. episode 1700.000000, reward total was -11.000000. running mean: -12.015890\n","resetting env. episode 1701.000000, reward total was -17.000000. running mean: -12.065731\n","resetting env. episode 1702.000000, reward total was -6.000000. running mean: -12.005073\n","resetting env. episode 1703.000000, reward total was -13.000000. running mean: -12.015023\n","resetting env. episode 1704.000000, reward total was -14.000000. running mean: -12.034872\n","resetting env. episode 1705.000000, reward total was -11.000000. running mean: -12.024524\n","resetting env. episode 1706.000000, reward total was -15.000000. running mean: -12.054279\n","resetting env. episode 1707.000000, reward total was -13.000000. running mean: -12.063736\n","resetting env. episode 1708.000000, reward total was -8.000000. running mean: -12.023098\n","resetting env. episode 1709.000000, reward total was -9.000000. running mean: -11.992867\n","resetting env. episode 1710.000000, reward total was -11.000000. running mean: -11.982939\n","resetting env. episode 1711.000000, reward total was -10.000000. running mean: -11.963109\n","resetting env. episode 1712.000000, reward total was -15.000000. running mean: -11.993478\n","resetting env. episode 1713.000000, reward total was -10.000000. running mean: -11.973543\n","resetting env. episode 1714.000000, reward total was -13.000000. running mean: -11.983808\n","resetting env. episode 1715.000000, reward total was -11.000000. running mean: -11.973970\n","resetting env. episode 1716.000000, reward total was -11.000000. running mean: -11.964230\n","resetting env. episode 1717.000000, reward total was -15.000000. running mean: -11.994588\n","resetting env. episode 1718.000000, reward total was -12.000000. running mean: -11.994642\n","resetting env. episode 1719.000000, reward total was -4.000000. running mean: -11.914696\n","resetting env. episode 1720.000000, reward total was -14.000000. running mean: -11.935549\n","resetting env. episode 1721.000000, reward total was -13.000000. running mean: -11.946193\n","resetting env. episode 1722.000000, reward total was -17.000000. running mean: -11.996731\n","resetting env. episode 1723.000000, reward total was -4.000000. running mean: -11.916764\n","resetting env. episode 1724.000000, reward total was -5.000000. running mean: -11.847596\n","resetting env. episode 1725.000000, reward total was -9.000000. running mean: -11.819120\n","resetting env. episode 1726.000000, reward total was -11.000000. running mean: -11.810929\n","resetting env. episode 1727.000000, reward total was -15.000000. running mean: -11.842820\n","resetting env. episode 1728.000000, reward total was -13.000000. running mean: -11.854392\n","resetting env. episode 1729.000000, reward total was -9.000000. running mean: -11.825848\n","resetting env. episode 1730.000000, reward total was -13.000000. running mean: -11.837589\n","resetting env. episode 1731.000000, reward total was -8.000000. running mean: -11.799213\n","resetting env. episode 1732.000000, reward total was -15.000000. running mean: -11.831221\n","resetting env. episode 1733.000000, reward total was -17.000000. running mean: -11.882909\n","resetting env. episode 1734.000000, reward total was -14.000000. running mean: -11.904080\n","resetting env. episode 1735.000000, reward total was -12.000000. running mean: -11.905039\n","resetting env. episode 1736.000000, reward total was -13.000000. running mean: -11.915989\n","resetting env. episode 1737.000000, reward total was -9.000000. running mean: -11.886829\n","resetting env. episode 1738.000000, reward total was -12.000000. running mean: -11.887961\n","resetting env. episode 1739.000000, reward total was -13.000000. running mean: -11.899081\n","resetting env. episode 1740.000000, reward total was -6.000000. running mean: -11.840090\n","resetting env. episode 1741.000000, reward total was -13.000000. running mean: -11.851689\n","resetting env. episode 1742.000000, reward total was -12.000000. running mean: -11.853172\n","resetting env. episode 1743.000000, reward total was -15.000000. running mean: -11.884641\n","resetting env. episode 1744.000000, reward total was -19.000000. running mean: -11.955794\n","resetting env. episode 1745.000000, reward total was -10.000000. running mean: -11.936236\n","resetting env. episode 1746.000000, reward total was -9.000000. running mean: -11.906874\n","resetting env. episode 1747.000000, reward total was -18.000000. running mean: -11.967805\n","resetting env. episode 1748.000000, reward total was -13.000000. running mean: -11.978127\n","resetting env. episode 1749.000000, reward total was -19.000000. running mean: -12.048346\n","resetting env. episode 1750.000000, reward total was -9.000000. running mean: -12.017862\n","resetting env. episode 1751.000000, reward total was -12.000000. running mean: -12.017684\n","resetting env. episode 1752.000000, reward total was -6.000000. running mean: -11.957507\n","resetting env. episode 1753.000000, reward total was -15.000000. running mean: -11.987932\n","resetting env. episode 1754.000000, reward total was -17.000000. running mean: -12.038053\n","resetting env. episode 1755.000000, reward total was -10.000000. running mean: -12.017672\n","resetting env. episode 1756.000000, reward total was -9.000000. running mean: -11.987495\n","resetting env. episode 1757.000000, reward total was -13.000000. running mean: -11.997620\n","resetting env. episode 1758.000000, reward total was -12.000000. running mean: -11.997644\n","resetting env. episode 1759.000000, reward total was -11.000000. running mean: -11.987668\n","resetting env. episode 1760.000000, reward total was -11.000000. running mean: -11.977791\n","resetting env. episode 1761.000000, reward total was -7.000000. running mean: -11.928013\n","resetting env. episode 1762.000000, reward total was -11.000000. running mean: -11.918733\n","resetting env. episode 1763.000000, reward total was -17.000000. running mean: -11.969546\n","resetting env. episode 1764.000000, reward total was -10.000000. running mean: -11.949850\n","resetting env. episode 1765.000000, reward total was -14.000000. running mean: -11.970352\n","resetting env. episode 1766.000000, reward total was -11.000000. running mean: -11.960648\n","resetting env. episode 1767.000000, reward total was -15.000000. running mean: -11.991042\n","resetting env. episode 1768.000000, reward total was -15.000000. running mean: -12.021131\n","resetting env. episode 1769.000000, reward total was -7.000000. running mean: -11.970920\n","resetting env. episode 1770.000000, reward total was -5.000000. running mean: -11.901211\n","resetting env. episode 1771.000000, reward total was -13.000000. running mean: -11.912199\n","resetting env. episode 1772.000000, reward total was -17.000000. running mean: -11.963077\n","resetting env. episode 1773.000000, reward total was -15.000000. running mean: -11.993446\n","resetting env. episode 1774.000000, reward total was -11.000000. running mean: -11.983511\n","resetting env. episode 1775.000000, reward total was -3.000000. running mean: -11.893676\n","resetting env. episode 1776.000000, reward total was -15.000000. running mean: -11.924740\n","resetting env. episode 1777.000000, reward total was -5.000000. running mean: -11.855492\n","resetting env. episode 1778.000000, reward total was -7.000000. running mean: -11.806937\n","resetting env. episode 1779.000000, reward total was -9.000000. running mean: -11.778868\n","resetting env. episode 1780.000000, reward total was -17.000000. running mean: -11.831079\n","resetting env. episode 1781.000000, reward total was -17.000000. running mean: -11.882768\n","resetting env. episode 1782.000000, reward total was -11.000000. running mean: -11.873941\n","resetting env. episode 1783.000000, reward total was -15.000000. running mean: -11.905201\n","resetting env. episode 1784.000000, reward total was -13.000000. running mean: -11.916149\n","resetting env. episode 1785.000000, reward total was -10.000000. running mean: -11.896988\n","resetting env. episode 1786.000000, reward total was -14.000000. running mean: -11.918018\n","resetting env. episode 1787.000000, reward total was -11.000000. running mean: -11.908838\n","resetting env. episode 1788.000000, reward total was -13.000000. running mean: -11.919749\n","resetting env. episode 1789.000000, reward total was -11.000000. running mean: -11.910552\n","resetting env. episode 1790.000000, reward total was -9.000000. running mean: -11.881446\n","resetting env. episode 1791.000000, reward total was -11.000000. running mean: -11.872632\n","resetting env. episode 1792.000000, reward total was -11.000000. running mean: -11.863906\n","resetting env. episode 1793.000000, reward total was -14.000000. running mean: -11.885267\n","resetting env. episode 1794.000000, reward total was -14.000000. running mean: -11.906414\n","resetting env. episode 1795.000000, reward total was -7.000000. running mean: -11.857350\n","resetting env. episode 1796.000000, reward total was -14.000000. running mean: -11.878776\n","resetting env. episode 1797.000000, reward total was -9.000000. running mean: -11.849988\n","resetting env. episode 1798.000000, reward total was -1.000000. running mean: -11.741489\n","resetting env. episode 1799.000000, reward total was -11.000000. running mean: -11.734074\n","resetting env. episode 1800.000000, reward total was -13.000000. running mean: -11.746733\n","resetting env. episode 1801.000000, reward total was -11.000000. running mean: -11.739266\n","resetting env. episode 1802.000000, reward total was -10.000000. running mean: -11.721873\n","resetting env. episode 1803.000000, reward total was -10.000000. running mean: -11.704654\n","resetting env. episode 1804.000000, reward total was -13.000000. running mean: -11.717608\n","resetting env. episode 1805.000000, reward total was -8.000000. running mean: -11.680432\n","resetting env. episode 1806.000000, reward total was -17.000000. running mean: -11.733627\n","resetting env. episode 1807.000000, reward total was -11.000000. running mean: -11.726291\n","resetting env. episode 1808.000000, reward total was -19.000000. running mean: -11.799028\n","resetting env. episode 1809.000000, reward total was -12.000000. running mean: -11.801038\n","resetting env. episode 1810.000000, reward total was -6.000000. running mean: -11.743027\n","resetting env. episode 1811.000000, reward total was -14.000000. running mean: -11.765597\n","resetting env. episode 1812.000000, reward total was -11.000000. running mean: -11.757941\n","resetting env. episode 1813.000000, reward total was -11.000000. running mean: -11.750362\n","resetting env. episode 1814.000000, reward total was -13.000000. running mean: -11.762858\n","resetting env. episode 1815.000000, reward total was -4.000000. running mean: -11.685230\n","resetting env. episode 1816.000000, reward total was -11.000000. running mean: -11.678377\n","resetting env. episode 1817.000000, reward total was -11.000000. running mean: -11.671594\n","resetting env. episode 1818.000000, reward total was -7.000000. running mean: -11.624878\n","resetting env. episode 1819.000000, reward total was -15.000000. running mean: -11.658629\n","resetting env. episode 1820.000000, reward total was -6.000000. running mean: -11.602043\n","resetting env. episode 1821.000000, reward total was -9.000000. running mean: -11.576022\n","resetting env. episode 1822.000000, reward total was -15.000000. running mean: -11.610262\n","resetting env. episode 1823.000000, reward total was -6.000000. running mean: -11.554159\n","resetting env. episode 1824.000000, reward total was -7.000000. running mean: -11.508618\n","resetting env. episode 1825.000000, reward total was -13.000000. running mean: -11.523531\n","resetting env. episode 1826.000000, reward total was -1.000000. running mean: -11.418296\n","resetting env. episode 1827.000000, reward total was -10.000000. running mean: -11.404113\n","resetting env. episode 1828.000000, reward total was -11.000000. running mean: -11.400072\n","resetting env. episode 1829.000000, reward total was -13.000000. running mean: -11.416071\n","resetting env. episode 1830.000000, reward total was -13.000000. running mean: -11.431911\n","resetting env. episode 1831.000000, reward total was -13.000000. running mean: -11.447592\n","resetting env. episode 1832.000000, reward total was -12.000000. running mean: -11.453116\n","resetting env. episode 1833.000000, reward total was -11.000000. running mean: -11.448584\n","resetting env. episode 1834.000000, reward total was -9.000000. running mean: -11.424099\n","resetting env. episode 1835.000000, reward total was -7.000000. running mean: -11.379858\n","resetting env. episode 1836.000000, reward total was -13.000000. running mean: -11.396059\n","resetting env. episode 1837.000000, reward total was -12.000000. running mean: -11.402098\n","resetting env. episode 1838.000000, reward total was 2.000000. running mean: -11.268077\n","resetting env. episode 1839.000000, reward total was -17.000000. running mean: -11.325397\n","resetting env. episode 1840.000000, reward total was -8.000000. running mean: -11.292143\n","resetting env. episode 1841.000000, reward total was -7.000000. running mean: -11.249221\n","resetting env. episode 1842.000000, reward total was -13.000000. running mean: -11.266729\n","resetting env. episode 1843.000000, reward total was -13.000000. running mean: -11.284062\n","resetting env. episode 1844.000000, reward total was -13.000000. running mean: -11.301221\n","resetting env. episode 1845.000000, reward total was -7.000000. running mean: -11.258209\n","resetting env. episode 1846.000000, reward total was -17.000000. running mean: -11.315627\n","resetting env. episode 1847.000000, reward total was -10.000000. running mean: -11.302471\n","resetting env. episode 1848.000000, reward total was -16.000000. running mean: -11.349446\n","resetting env. episode 1849.000000, reward total was -13.000000. running mean: -11.365951\n","resetting env. episode 1850.000000, reward total was -13.000000. running mean: -11.382292\n","resetting env. episode 1851.000000, reward total was -7.000000. running mean: -11.338469\n","resetting env. episode 1852.000000, reward total was -15.000000. running mean: -11.375084\n","resetting env. episode 1853.000000, reward total was -6.000000. running mean: -11.321333\n","resetting env. episode 1854.000000, reward total was -10.000000. running mean: -11.308120\n","resetting env. episode 1855.000000, reward total was -11.000000. running mean: -11.305039\n","resetting env. episode 1856.000000, reward total was -10.000000. running mean: -11.291989\n","resetting env. episode 1857.000000, reward total was -11.000000. running mean: -11.289069\n","resetting env. episode 1858.000000, reward total was -10.000000. running mean: -11.276178\n","resetting env. episode 1859.000000, reward total was -15.000000. running mean: -11.313416\n","resetting env. episode 1860.000000, reward total was -13.000000. running mean: -11.330282\n","resetting env. episode 1861.000000, reward total was -13.000000. running mean: -11.346979\n","resetting env. episode 1862.000000, reward total was -12.000000. running mean: -11.353509\n","resetting env. episode 1863.000000, reward total was -12.000000. running mean: -11.359974\n","resetting env. episode 1864.000000, reward total was -13.000000. running mean: -11.376375\n","resetting env. episode 1865.000000, reward total was -18.000000. running mean: -11.442611\n","resetting env. episode 1866.000000, reward total was -8.000000. running mean: -11.408185\n","resetting env. episode 1867.000000, reward total was -3.000000. running mean: -11.324103\n","resetting env. episode 1868.000000, reward total was -14.000000. running mean: -11.350862\n","resetting env. episode 1869.000000, reward total was -14.000000. running mean: -11.377353\n","resetting env. episode 1870.000000, reward total was -14.000000. running mean: -11.403580\n","resetting env. episode 1871.000000, reward total was -10.000000. running mean: -11.389544\n","resetting env. episode 1872.000000, reward total was -15.000000. running mean: -11.425648\n","resetting env. episode 1873.000000, reward total was -15.000000. running mean: -11.461392\n","resetting env. episode 1874.000000, reward total was -8.000000. running mean: -11.426778\n","resetting env. episode 1875.000000, reward total was -5.000000. running mean: -11.362510\n","resetting env. episode 1876.000000, reward total was -13.000000. running mean: -11.378885\n","resetting env. episode 1877.000000, reward total was -16.000000. running mean: -11.425096\n","resetting env. episode 1878.000000, reward total was -18.000000. running mean: -11.490845\n","resetting env. episode 1879.000000, reward total was -12.000000. running mean: -11.495937\n","resetting env. episode 1880.000000, reward total was -9.000000. running mean: -11.470978\n","resetting env. episode 1881.000000, reward total was -13.000000. running mean: -11.486268\n","resetting env. episode 1882.000000, reward total was -13.000000. running mean: -11.501405\n","resetting env. episode 1883.000000, reward total was -15.000000. running mean: -11.536391\n","resetting env. episode 1884.000000, reward total was -12.000000. running mean: -11.541027\n","resetting env. episode 1885.000000, reward total was -5.000000. running mean: -11.475617\n","resetting env. episode 1886.000000, reward total was -12.000000. running mean: -11.480861\n","resetting env. episode 1887.000000, reward total was -12.000000. running mean: -11.486052\n","resetting env. episode 1888.000000, reward total was -14.000000. running mean: -11.511192\n","resetting env. episode 1889.000000, reward total was -11.000000. running mean: -11.506080\n","resetting env. episode 1890.000000, reward total was -8.000000. running mean: -11.471019\n","resetting env. episode 1891.000000, reward total was -15.000000. running mean: -11.506309\n","resetting env. episode 1892.000000, reward total was -7.000000. running mean: -11.461246\n","resetting env. episode 1893.000000, reward total was -17.000000. running mean: -11.516633\n","resetting env. episode 1894.000000, reward total was -8.000000. running mean: -11.481467\n","resetting env. episode 1895.000000, reward total was -11.000000. running mean: -11.476652\n","resetting env. episode 1896.000000, reward total was -18.000000. running mean: -11.541886\n","resetting env. episode 1897.000000, reward total was -13.000000. running mean: -11.556467\n","resetting env. episode 1898.000000, reward total was -9.000000. running mean: -11.530902\n","resetting env. episode 1899.000000, reward total was -15.000000. running mean: -11.565593\n","resetting env. episode 1900.000000, reward total was -14.000000. running mean: -11.589937\n","resetting env. episode 1901.000000, reward total was -14.000000. running mean: -11.614038\n","resetting env. episode 1902.000000, reward total was -11.000000. running mean: -11.607897\n","resetting env. episode 1903.000000, reward total was -11.000000. running mean: -11.601818\n","resetting env. episode 1904.000000, reward total was -1.000000. running mean: -11.495800\n","resetting env. episode 1905.000000, reward total was -12.000000. running mean: -11.500842\n","resetting env. episode 1906.000000, reward total was -6.000000. running mean: -11.445834\n","resetting env. episode 1907.000000, reward total was -13.000000. running mean: -11.461375\n","resetting env. episode 1908.000000, reward total was -7.000000. running mean: -11.416762\n","resetting env. episode 1909.000000, reward total was -7.000000. running mean: -11.372594\n","resetting env. episode 1910.000000, reward total was -18.000000. running mean: -11.438868\n","resetting env. episode 1911.000000, reward total was -8.000000. running mean: -11.404479\n","resetting env. episode 1912.000000, reward total was -13.000000. running mean: -11.420435\n","resetting env. episode 1913.000000, reward total was -15.000000. running mean: -11.456230\n","resetting env. episode 1914.000000, reward total was -13.000000. running mean: -11.471668\n","resetting env. episode 1915.000000, reward total was -12.000000. running mean: -11.476951\n","resetting env. episode 1916.000000, reward total was -19.000000. running mean: -11.552182\n","resetting env. episode 1917.000000, reward total was -15.000000. running mean: -11.586660\n","resetting env. episode 1918.000000, reward total was -12.000000. running mean: -11.590793\n","resetting env. episode 1919.000000, reward total was -10.000000. running mean: -11.574885\n","resetting env. episode 1920.000000, reward total was -11.000000. running mean: -11.569137\n","resetting env. episode 1921.000000, reward total was -16.000000. running mean: -11.613445\n","resetting env. episode 1922.000000, reward total was -6.000000. running mean: -11.557311\n","resetting env. episode 1923.000000, reward total was -1.000000. running mean: -11.451738\n","resetting env. episode 1924.000000, reward total was -13.000000. running mean: -11.467220\n","resetting env. episode 1925.000000, reward total was -10.000000. running mean: -11.452548\n","resetting env. episode 1926.000000, reward total was -17.000000. running mean: -11.508023\n","resetting env. episode 1927.000000, reward total was -13.000000. running mean: -11.522942\n","resetting env. episode 1928.000000, reward total was -11.000000. running mean: -11.517713\n","resetting env. episode 1929.000000, reward total was -11.000000. running mean: -11.512536\n","resetting env. episode 1930.000000, reward total was -8.000000. running mean: -11.477410\n","resetting env. episode 1931.000000, reward total was -12.000000. running mean: -11.482636\n","resetting env. episode 1932.000000, reward total was -14.000000. running mean: -11.507810\n","resetting env. episode 1933.000000, reward total was -15.000000. running mean: -11.542732\n","resetting env. episode 1934.000000, reward total was -13.000000. running mean: -11.557305\n","resetting env. episode 1935.000000, reward total was -17.000000. running mean: -11.611732\n","resetting env. episode 1936.000000, reward total was -12.000000. running mean: -11.615614\n","resetting env. episode 1937.000000, reward total was -19.000000. running mean: -11.689458\n","resetting env. episode 1938.000000, reward total was -13.000000. running mean: -11.702564\n","resetting env. episode 1939.000000, reward total was -9.000000. running mean: -11.675538\n","resetting env. episode 1940.000000, reward total was -11.000000. running mean: -11.668783\n","resetting env. episode 1941.000000, reward total was -8.000000. running mean: -11.632095\n","resetting env. episode 1942.000000, reward total was -10.000000. running mean: -11.615774\n","resetting env. episode 1943.000000, reward total was -18.000000. running mean: -11.679616\n","resetting env. episode 1944.000000, reward total was -14.000000. running mean: -11.702820\n","resetting env. episode 1945.000000, reward total was -8.000000. running mean: -11.665792\n","resetting env. episode 1946.000000, reward total was -13.000000. running mean: -11.679134\n","resetting env. episode 1947.000000, reward total was -15.000000. running mean: -11.712342\n","resetting env. episode 1948.000000, reward total was -5.000000. running mean: -11.645219\n","resetting env. episode 1949.000000, reward total was -11.000000. running mean: -11.638767\n","resetting env. episode 1950.000000, reward total was -17.000000. running mean: -11.692379\n","resetting env. episode 1951.000000, reward total was -13.000000. running mean: -11.705455\n","resetting env. episode 1952.000000, reward total was -8.000000. running mean: -11.668401\n","resetting env. episode 1953.000000, reward total was -16.000000. running mean: -11.711717\n","resetting env. episode 1954.000000, reward total was -12.000000. running mean: -11.714600\n","resetting env. episode 1955.000000, reward total was -13.000000. running mean: -11.727454\n","resetting env. episode 1956.000000, reward total was -12.000000. running mean: -11.730179\n","resetting env. episode 1957.000000, reward total was -18.000000. running mean: -11.792877\n","resetting env. episode 1958.000000, reward total was -8.000000. running mean: -11.754948\n","resetting env. episode 1959.000000, reward total was -10.000000. running mean: -11.737399\n","resetting env. episode 1960.000000, reward total was -11.000000. running mean: -11.730025\n","resetting env. episode 1961.000000, reward total was -14.000000. running mean: -11.752725\n","resetting env. episode 1962.000000, reward total was -7.000000. running mean: -11.705198\n","resetting env. episode 1963.000000, reward total was -11.000000. running mean: -11.698146\n","resetting env. episode 1964.000000, reward total was -16.000000. running mean: -11.741164\n","resetting env. episode 1965.000000, reward total was -10.000000. running mean: -11.723752\n","resetting env. episode 1966.000000, reward total was -11.000000. running mean: -11.716515\n","resetting env. episode 1967.000000, reward total was -6.000000. running mean: -11.659350\n","resetting env. episode 1968.000000, reward total was -11.000000. running mean: -11.652756\n","resetting env. episode 1969.000000, reward total was -12.000000. running mean: -11.656229\n","resetting env. episode 1970.000000, reward total was -12.000000. running mean: -11.659666\n","resetting env. episode 1971.000000, reward total was -11.000000. running mean: -11.653070\n","resetting env. episode 1972.000000, reward total was -6.000000. running mean: -11.596539\n","resetting env. episode 1973.000000, reward total was -9.000000. running mean: -11.570574\n","resetting env. episode 1974.000000, reward total was -8.000000. running mean: -11.534868\n","resetting env. episode 1975.000000, reward total was -7.000000. running mean: -11.489519\n","resetting env. episode 1976.000000, reward total was -15.000000. running mean: -11.524624\n","resetting env. episode 1977.000000, reward total was -7.000000. running mean: -11.479378\n","resetting env. episode 1978.000000, reward total was -15.000000. running mean: -11.514584\n","resetting env. episode 1979.000000, reward total was -14.000000. running mean: -11.539438\n","resetting env. episode 1980.000000, reward total was -16.000000. running mean: -11.584044\n","resetting env. episode 1981.000000, reward total was -6.000000. running mean: -11.528203\n","resetting env. episode 1982.000000, reward total was -8.000000. running mean: -11.492921\n","resetting env. episode 1983.000000, reward total was -7.000000. running mean: -11.447992\n","resetting env. episode 1984.000000, reward total was -19.000000. running mean: -11.523512\n","resetting env. episode 1985.000000, reward total was -12.000000. running mean: -11.528277\n","resetting env. episode 1986.000000, reward total was -9.000000. running mean: -11.502994\n","resetting env. episode 1987.000000, reward total was -11.000000. running mean: -11.497964\n","resetting env. episode 1988.000000, reward total was -6.000000. running mean: -11.442985\n","resetting env. episode 1989.000000, reward total was -11.000000. running mean: -11.438555\n","resetting env. episode 1990.000000, reward total was -19.000000. running mean: -11.514169\n","resetting env. episode 1991.000000, reward total was -8.000000. running mean: -11.479028\n","resetting env. episode 1992.000000, reward total was -13.000000. running mean: -11.494237\n","resetting env. episode 1993.000000, reward total was -15.000000. running mean: -11.529295\n","resetting env. episode 1994.000000, reward total was -14.000000. running mean: -11.554002\n","resetting env. episode 1995.000000, reward total was -15.000000. running mean: -11.588462\n","resetting env. episode 1996.000000, reward total was -9.000000. running mean: -11.562577\n","resetting env. episode 1997.000000, reward total was 1.000000. running mean: -11.436952\n","resetting env. episode 1998.000000, reward total was -10.000000. running mean: -11.422582\n","resetting env. episode 1999.000000, reward total was -9.000000. running mean: -11.398356\n","resetting env. episode 2000.000000, reward total was -12.000000. running mean: -11.404373\n","resetting env. episode 2001.000000, reward total was -17.000000. running mean: -11.460329\n","resetting env. episode 2002.000000, reward total was -9.000000. running mean: -11.435726\n","resetting env. episode 2003.000000, reward total was -11.000000. running mean: -11.431368\n","resetting env. episode 2004.000000, reward total was -7.000000. running mean: -11.387055\n","resetting env. episode 2005.000000, reward total was -13.000000. running mean: -11.403184\n","resetting env. episode 2006.000000, reward total was -13.000000. running mean: -11.419152\n","resetting env. episode 2007.000000, reward total was -8.000000. running mean: -11.384961\n","resetting env. episode 2008.000000, reward total was -8.000000. running mean: -11.351111\n","resetting env. episode 2009.000000, reward total was -2.000000. running mean: -11.257600\n","resetting env. episode 2010.000000, reward total was -3.000000. running mean: -11.175024\n","resetting env. episode 2011.000000, reward total was -9.000000. running mean: -11.153274\n","resetting env. episode 2012.000000, reward total was -12.000000. running mean: -11.161741\n","resetting env. episode 2013.000000, reward total was -9.000000. running mean: -11.140124\n","resetting env. episode 2014.000000, reward total was -7.000000. running mean: -11.098723\n","resetting env. episode 2015.000000, reward total was -8.000000. running mean: -11.067735\n","resetting env. episode 2016.000000, reward total was -7.000000. running mean: -11.027058\n","resetting env. episode 2017.000000, reward total was -10.000000. running mean: -11.016787\n","resetting env. episode 2018.000000, reward total was -12.000000. running mean: -11.026619\n","resetting env. episode 2019.000000, reward total was -17.000000. running mean: -11.086353\n","resetting env. episode 2020.000000, reward total was -11.000000. running mean: -11.085490\n","resetting env. episode 2021.000000, reward total was -10.000000. running mean: -11.074635\n","resetting env. episode 2022.000000, reward total was -13.000000. running mean: -11.093889\n","resetting env. episode 2023.000000, reward total was -5.000000. running mean: -11.032950\n","resetting env. episode 2024.000000, reward total was -10.000000. running mean: -11.022620\n","resetting env. episode 2025.000000, reward total was -16.000000. running mean: -11.072394\n","resetting env. episode 2026.000000, reward total was -11.000000. running mean: -11.071670\n","resetting env. episode 2027.000000, reward total was -9.000000. running mean: -11.050953\n","resetting env. episode 2028.000000, reward total was -11.000000. running mean: -11.050444\n","resetting env. episode 2029.000000, reward total was -7.000000. running mean: -11.009939\n","resetting env. episode 2030.000000, reward total was -13.000000. running mean: -11.029840\n","resetting env. episode 2031.000000, reward total was -16.000000. running mean: -11.079542\n","resetting env. episode 2032.000000, reward total was -2.000000. running mean: -10.988746\n","resetting env. episode 2033.000000, reward total was -13.000000. running mean: -11.008859\n","resetting env. episode 2034.000000, reward total was -18.000000. running mean: -11.078770\n","resetting env. episode 2035.000000, reward total was -10.000000. running mean: -11.067982\n","resetting env. episode 2036.000000, reward total was -11.000000. running mean: -11.067303\n","resetting env. episode 2037.000000, reward total was -13.000000. running mean: -11.086630\n","resetting env. episode 2038.000000, reward total was -9.000000. running mean: -11.065763\n","resetting env. episode 2039.000000, reward total was -8.000000. running mean: -11.035106\n","resetting env. episode 2040.000000, reward total was 2.000000. running mean: -10.904755\n","resetting env. episode 2041.000000, reward total was -7.000000. running mean: -10.865707\n","resetting env. episode 2042.000000, reward total was -15.000000. running mean: -10.907050\n","resetting env. episode 2043.000000, reward total was -16.000000. running mean: -10.957979\n","resetting env. episode 2044.000000, reward total was -7.000000. running mean: -10.918400\n","resetting env. episode 2045.000000, reward total was -15.000000. running mean: -10.959216\n","resetting env. episode 2046.000000, reward total was -12.000000. running mean: -10.969623\n","resetting env. episode 2047.000000, reward total was -5.000000. running mean: -10.909927\n","resetting env. episode 2048.000000, reward total was -7.000000. running mean: -10.870828\n","resetting env. episode 2049.000000, reward total was -13.000000. running mean: -10.892120\n","resetting env. episode 2050.000000, reward total was -16.000000. running mean: -10.943198\n","resetting env. episode 2051.000000, reward total was -7.000000. running mean: -10.903766\n","resetting env. episode 2052.000000, reward total was -14.000000. running mean: -10.934729\n","resetting env. episode 2053.000000, reward total was -11.000000. running mean: -10.935382\n","resetting env. episode 2054.000000, reward total was -11.000000. running mean: -10.936028\n","resetting env. episode 2055.000000, reward total was -15.000000. running mean: -10.976667\n","resetting env. episode 2056.000000, reward total was -17.000000. running mean: -11.036901\n","resetting env. episode 2057.000000, reward total was -12.000000. running mean: -11.046532\n","resetting env. episode 2058.000000, reward total was -12.000000. running mean: -11.056066\n","resetting env. episode 2059.000000, reward total was -6.000000. running mean: -11.005506\n","resetting env. episode 2060.000000, reward total was -8.000000. running mean: -10.975451\n","resetting env. episode 2061.000000, reward total was -10.000000. running mean: -10.965696\n","resetting env. episode 2062.000000, reward total was -9.000000. running mean: -10.946039\n","resetting env. episode 2063.000000, reward total was -13.000000. running mean: -10.966579\n","resetting env. episode 2064.000000, reward total was -13.000000. running mean: -10.986913\n","resetting env. episode 2065.000000, reward total was -10.000000. running mean: -10.977044\n","resetting env. episode 2066.000000, reward total was -9.000000. running mean: -10.957274\n","resetting env. episode 2067.000000, reward total was -14.000000. running mean: -10.987701\n","resetting env. episode 2068.000000, reward total was -10.000000. running mean: -10.977824\n","resetting env. episode 2069.000000, reward total was -12.000000. running mean: -10.988046\n","resetting env. episode 2070.000000, reward total was -11.000000. running mean: -10.988165\n","resetting env. episode 2071.000000, reward total was -9.000000. running mean: -10.968283\n","resetting env. episode 2072.000000, reward total was -17.000000. running mean: -11.028601\n","resetting env. episode 2073.000000, reward total was -4.000000. running mean: -10.958315\n","resetting env. episode 2074.000000, reward total was -5.000000. running mean: -10.898731\n","resetting env. episode 2075.000000, reward total was -13.000000. running mean: -10.919744\n","resetting env. episode 2076.000000, reward total was -14.000000. running mean: -10.950547\n","resetting env. episode 2077.000000, reward total was -7.000000. running mean: -10.911041\n","resetting env. episode 2078.000000, reward total was -4.000000. running mean: -10.841931\n","resetting env. episode 2079.000000, reward total was -12.000000. running mean: -10.853511\n","resetting env. episode 2080.000000, reward total was -14.000000. running mean: -10.884976\n","resetting env. episode 2081.000000, reward total was -16.000000. running mean: -10.936127\n","resetting env. episode 2082.000000, reward total was -17.000000. running mean: -10.996765\n","resetting env. episode 2083.000000, reward total was -9.000000. running mean: -10.976798\n","resetting env. episode 2084.000000, reward total was -7.000000. running mean: -10.937030\n","resetting env. episode 2085.000000, reward total was -6.000000. running mean: -10.887659\n","resetting env. episode 2086.000000, reward total was -15.000000. running mean: -10.928783\n","resetting env. episode 2087.000000, reward total was -6.000000. running mean: -10.879495\n","resetting env. episode 2088.000000, reward total was -14.000000. running mean: -10.910700\n","resetting env. episode 2089.000000, reward total was -6.000000. running mean: -10.861593\n","resetting env. episode 2090.000000, reward total was -14.000000. running mean: -10.892977\n","resetting env. episode 2091.000000, reward total was -14.000000. running mean: -10.924047\n","resetting env. episode 2092.000000, reward total was -5.000000. running mean: -10.864807\n","resetting env. episode 2093.000000, reward total was -14.000000. running mean: -10.896159\n","resetting env. episode 2094.000000, reward total was -14.000000. running mean: -10.927197\n","resetting env. episode 2095.000000, reward total was -17.000000. running mean: -10.987925\n","resetting env. episode 2096.000000, reward total was -11.000000. running mean: -10.988046\n","resetting env. episode 2097.000000, reward total was -13.000000. running mean: -11.008166\n","resetting env. episode 2098.000000, reward total was -14.000000. running mean: -11.038084\n","resetting env. episode 2099.000000, reward total was -13.000000. running mean: -11.057703\n","resetting env. episode 2100.000000, reward total was -3.000000. running mean: -10.977126\n","resetting env. episode 2101.000000, reward total was -11.000000. running mean: -10.977355\n","resetting env. episode 2102.000000, reward total was -15.000000. running mean: -11.017581\n","resetting env. episode 2103.000000, reward total was -13.000000. running mean: -11.037405\n","resetting env. episode 2104.000000, reward total was -12.000000. running mean: -11.047031\n","resetting env. episode 2105.000000, reward total was -4.000000. running mean: -10.976561\n","resetting env. episode 2106.000000, reward total was -6.000000. running mean: -10.926795\n","resetting env. episode 2107.000000, reward total was -14.000000. running mean: -10.957527\n","resetting env. episode 2108.000000, reward total was -6.000000. running mean: -10.907952\n","resetting env. episode 2109.000000, reward total was -10.000000. running mean: -10.898873\n","resetting env. episode 2110.000000, reward total was -13.000000. running mean: -10.919884\n","resetting env. episode 2111.000000, reward total was -9.000000. running mean: -10.900685\n","resetting env. episode 2112.000000, reward total was -6.000000. running mean: -10.851678\n","resetting env. episode 2113.000000, reward total was -13.000000. running mean: -10.873161\n","resetting env. episode 2114.000000, reward total was -14.000000. running mean: -10.904430\n","resetting env. episode 2115.000000, reward total was -9.000000. running mean: -10.885386\n","resetting env. episode 2116.000000, reward total was -7.000000. running mean: -10.846532\n","resetting env. episode 2117.000000, reward total was -14.000000. running mean: -10.878066\n","resetting env. episode 2118.000000, reward total was -17.000000. running mean: -10.939286\n","resetting env. episode 2119.000000, reward total was -10.000000. running mean: -10.929893\n","resetting env. episode 2120.000000, reward total was -10.000000. running mean: -10.920594\n","resetting env. episode 2121.000000, reward total was -11.000000. running mean: -10.921388\n","resetting env. episode 2122.000000, reward total was -16.000000. running mean: -10.972174\n","resetting env. episode 2123.000000, reward total was -16.000000. running mean: -11.022452\n","resetting env. episode 2124.000000, reward total was -13.000000. running mean: -11.042228\n","resetting env. episode 2125.000000, reward total was -12.000000. running mean: -11.051806\n","resetting env. episode 2126.000000, reward total was -12.000000. running mean: -11.061288\n","resetting env. episode 2127.000000, reward total was -12.000000. running mean: -11.070675\n","resetting env. episode 2128.000000, reward total was -12.000000. running mean: -11.079968\n","resetting env. episode 2129.000000, reward total was -14.000000. running mean: -11.109168\n","resetting env. episode 2130.000000, reward total was -9.000000. running mean: -11.088077\n","resetting env. episode 2131.000000, reward total was -16.000000. running mean: -11.137196\n","resetting env. episode 2132.000000, reward total was -5.000000. running mean: -11.075824\n","resetting env. episode 2133.000000, reward total was -9.000000. running mean: -11.055066\n","resetting env. episode 2134.000000, reward total was -13.000000. running mean: -11.074515\n","resetting env. episode 2135.000000, reward total was -17.000000. running mean: -11.133770\n","resetting env. episode 2136.000000, reward total was -13.000000. running mean: -11.152432\n","resetting env. episode 2137.000000, reward total was -8.000000. running mean: -11.120908\n","resetting env. episode 2138.000000, reward total was -3.000000. running mean: -11.039699\n","resetting env. episode 2139.000000, reward total was -5.000000. running mean: -10.979302\n","resetting env. episode 2140.000000, reward total was -12.000000. running mean: -10.989509\n","resetting env. episode 2141.000000, reward total was -5.000000. running mean: -10.929614\n","resetting env. episode 2142.000000, reward total was -13.000000. running mean: -10.950317\n","resetting env. episode 2143.000000, reward total was -3.000000. running mean: -10.870814\n","resetting env. episode 2144.000000, reward total was -11.000000. running mean: -10.872106\n","resetting env. episode 2145.000000, reward total was -20.000000. running mean: -10.963385\n","resetting env. episode 2146.000000, reward total was -8.000000. running mean: -10.933751\n","resetting env. episode 2147.000000, reward total was -4.000000. running mean: -10.864414\n","resetting env. episode 2148.000000, reward total was -9.000000. running mean: -10.845770\n","resetting env. episode 2149.000000, reward total was -7.000000. running mean: -10.807312\n","resetting env. episode 2150.000000, reward total was -10.000000. running mean: -10.799239\n","resetting env. episode 2151.000000, reward total was -12.000000. running mean: -10.811246\n","resetting env. episode 2152.000000, reward total was -10.000000. running mean: -10.803134\n","resetting env. episode 2153.000000, reward total was -10.000000. running mean: -10.795103\n","resetting env. episode 2154.000000, reward total was -5.000000. running mean: -10.737152\n","resetting env. episode 2155.000000, reward total was -8.000000. running mean: -10.709780\n","resetting env. episode 2156.000000, reward total was -11.000000. running mean: -10.712682\n","resetting env. episode 2157.000000, reward total was -13.000000. running mean: -10.735555\n","resetting env. episode 2158.000000, reward total was -6.000000. running mean: -10.688200\n","resetting env. episode 2159.000000, reward total was -12.000000. running mean: -10.701318\n","resetting env. episode 2160.000000, reward total was -5.000000. running mean: -10.644305\n","resetting env. episode 2161.000000, reward total was -6.000000. running mean: -10.597862\n","resetting env. episode 2162.000000, reward total was -13.000000. running mean: -10.621883\n","resetting env. episode 2163.000000, reward total was -14.000000. running mean: -10.655664\n","resetting env. episode 2164.000000, reward total was -16.000000. running mean: -10.709108\n","resetting env. episode 2165.000000, reward total was -14.000000. running mean: -10.742016\n","resetting env. episode 2166.000000, reward total was -9.000000. running mean: -10.724596\n","resetting env. episode 2167.000000, reward total was -7.000000. running mean: -10.687350\n","resetting env. episode 2168.000000, reward total was -6.000000. running mean: -10.640477\n","resetting env. episode 2169.000000, reward total was -11.000000. running mean: -10.644072\n","resetting env. episode 2170.000000, reward total was -3.000000. running mean: -10.567631\n","resetting env. episode 2171.000000, reward total was -11.000000. running mean: -10.571955\n","resetting env. episode 2172.000000, reward total was -13.000000. running mean: -10.596235\n","resetting env. episode 2173.000000, reward total was -11.000000. running mean: -10.600273\n","resetting env. episode 2174.000000, reward total was -9.000000. running mean: -10.584270\n","resetting env. episode 2175.000000, reward total was -11.000000. running mean: -10.588428\n","resetting env. episode 2176.000000, reward total was -13.000000. running mean: -10.612543\n","resetting env. episode 2177.000000, reward total was -7.000000. running mean: -10.576418\n","resetting env. episode 2178.000000, reward total was -15.000000. running mean: -10.620654\n","resetting env. episode 2179.000000, reward total was -11.000000. running mean: -10.624447\n","resetting env. episode 2180.000000, reward total was -15.000000. running mean: -10.668203\n","resetting env. episode 2181.000000, reward total was -5.000000. running mean: -10.611521\n","resetting env. episode 2182.000000, reward total was -13.000000. running mean: -10.635406\n","resetting env. episode 2183.000000, reward total was -2.000000. running mean: -10.549051\n","resetting env. episode 2184.000000, reward total was -7.000000. running mean: -10.513561\n","resetting env. episode 2185.000000, reward total was -9.000000. running mean: -10.498425\n","resetting env. episode 2186.000000, reward total was -16.000000. running mean: -10.553441\n","resetting env. episode 2187.000000, reward total was -15.000000. running mean: -10.597907\n","resetting env. episode 2188.000000, reward total was -4.000000. running mean: -10.531928\n","resetting env. episode 2189.000000, reward total was -11.000000. running mean: -10.536608\n","resetting env. episode 2190.000000, reward total was -13.000000. running mean: -10.561242\n","resetting env. episode 2191.000000, reward total was -11.000000. running mean: -10.565630\n","resetting env. episode 2192.000000, reward total was -5.000000. running mean: -10.509974\n","resetting env. episode 2193.000000, reward total was -7.000000. running mean: -10.474874\n","resetting env. episode 2194.000000, reward total was -10.000000. running mean: -10.470125\n","resetting env. episode 2195.000000, reward total was -7.000000. running mean: -10.435424\n","resetting env. episode 2196.000000, reward total was -15.000000. running mean: -10.481070\n","resetting env. episode 2197.000000, reward total was -8.000000. running mean: -10.456259\n","resetting env. episode 2198.000000, reward total was -10.000000. running mean: -10.451696\n","resetting env. episode 2199.000000, reward total was -15.000000. running mean: -10.497179\n","resetting env. episode 2200.000000, reward total was -11.000000. running mean: -10.502208\n","resetting env. episode 2201.000000, reward total was -11.000000. running mean: -10.507185\n","resetting env. episode 2202.000000, reward total was -3.000000. running mean: -10.432114\n","resetting env. episode 2203.000000, reward total was -11.000000. running mean: -10.437792\n","resetting env. episode 2204.000000, reward total was -6.000000. running mean: -10.393415\n","resetting env. episode 2205.000000, reward total was -2.000000. running mean: -10.309480\n","resetting env. episode 2206.000000, reward total was -10.000000. running mean: -10.306386\n","resetting env. episode 2207.000000, reward total was -2.000000. running mean: -10.223322\n","resetting env. episode 2208.000000, reward total was -16.000000. running mean: -10.281089\n","resetting env. episode 2209.000000, reward total was -15.000000. running mean: -10.328278\n","resetting env. episode 2210.000000, reward total was -9.000000. running mean: -10.314995\n","resetting env. episode 2211.000000, reward total was -9.000000. running mean: -10.301845\n","resetting env. episode 2212.000000, reward total was -8.000000. running mean: -10.278826\n","resetting env. episode 2213.000000, reward total was -7.000000. running mean: -10.246038\n","resetting env. episode 2214.000000, reward total was -18.000000. running mean: -10.323578\n","resetting env. episode 2215.000000, reward total was -10.000000. running mean: -10.320342\n","resetting env. episode 2216.000000, reward total was -12.000000. running mean: -10.337139\n","resetting env. episode 2217.000000, reward total was -8.000000. running mean: -10.313767\n","resetting env. episode 2218.000000, reward total was -11.000000. running mean: -10.320630\n","resetting env. episode 2219.000000, reward total was -12.000000. running mean: -10.337423\n","resetting env. episode 2220.000000, reward total was -10.000000. running mean: -10.334049\n","resetting env. episode 2221.000000, reward total was -9.000000. running mean: -10.320709\n","resetting env. episode 2222.000000, reward total was -9.000000. running mean: -10.307501\n","resetting env. episode 2223.000000, reward total was -13.000000. running mean: -10.334426\n","resetting env. episode 2224.000000, reward total was -6.000000. running mean: -10.291082\n","resetting env. episode 2225.000000, reward total was -2.000000. running mean: -10.208171\n","resetting env. episode 2226.000000, reward total was -5.000000. running mean: -10.156090\n","resetting env. episode 2227.000000, reward total was -7.000000. running mean: -10.124529\n","resetting env. episode 2228.000000, reward total was -14.000000. running mean: -10.163283\n","resetting env. episode 2229.000000, reward total was -11.000000. running mean: -10.171651\n","resetting env. episode 2230.000000, reward total was -15.000000. running mean: -10.219934\n","resetting env. episode 2231.000000, reward total was -14.000000. running mean: -10.257735\n"]}]},{"metadata":{"id":"ZJUybWUALvQz"},"cell_type":"code","source":["play_game(env, model)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"cHYCDYwhlVLV"},"cell_type":"code","source":["%time hist2 = train_model(env, model, total_episodes=1000)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"8fheN9DRlWXQ"},"cell_type":"code","source":["play_game(env, model)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"9AxOcQhIsKow"},"cell_type":"code","source":["%time hist3 = train_model(env, model, total_episodes=1000)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"w2NblmwDsL3y"},"cell_type":"code","source":["play_game(env, model)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"ZYA0HgMoO77a"},"cell_type":"code","source":["# import pickle\n","# pickle.dump(model, open('model.pkl', 'wb'))"],"execution_count":null,"outputs":[]},{"metadata":{"id":"2Vu9PonFR5NA"},"cell_type":"code","source":[""],"execution_count":null,"outputs":[]}]}